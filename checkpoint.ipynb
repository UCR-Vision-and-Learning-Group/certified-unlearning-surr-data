{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-14T09:30:26.626767Z",
     "start_time": "2024-12-14T09:30:24.858745Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import ConcatDataset, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "from src.data import get_train_test_datasets, get_dataloaders, get_retain_forget_datasets, get_exact_surr_datasets, get_class_ratios\n",
    "from src.train import train\n",
    "from src.eval import evaluate\n",
    "from src.utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:30:26.631305Z",
     "start_time": "2024-12-14T09:30:26.628112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ShallowModel(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.extractor = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.extractor(x))"
   ],
   "id": "c5a6fbe3a5fc3196",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:30:28.292245Z",
     "start_time": "2024-12-14T09:30:26.631981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gtransform = v2.Compose([\n",
    "    v2.Grayscale(),\n",
    "    v2.Resize((28, 28)),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "    v2.Lambda(lambda img: img.view(-1))\n",
    "])\n",
    "\n",
    "\n",
    "gtrain_dataset, gval_dataset = get_train_test_datasets('usps', gtransform)\n",
    "gtrain_loader, gval_loader = get_dataloaders([gtrain_dataset, gval_dataset], batch_size=256)"
   ],
   "id": "d4bbf1d2a79f3264",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:30:44.616582Z",
     "start_time": "2024-12-14T09:30:28.293620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ShallowModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(gtrain_loader, gval_loader, model, criterion, optimizer, num_epoch=10, device=device)\n",
    "evaluate(gval_loader, model, criterion, device=device)"
   ],
   "id": "b295c7399da2e718",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|██████████| 29/29 [00:01<00:00, 20.81batch/s, loss=0.193]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 21.14batch/s, acc=0.886, loss=0.578]\n",
      "train epoch 2: 100%|██████████| 29/29 [00:01<00:00, 23.53batch/s, loss=0.193]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.54batch/s, acc=0.906, loss=0.452]\n",
      "train epoch 3: 100%|██████████| 29/29 [00:01<00:00, 23.68batch/s, loss=0.152]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.13batch/s, acc=0.906, loss=0.35] \n",
      "train epoch 4: 100%|██████████| 29/29 [00:01<00:00, 23.51batch/s, loss=0.174]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.23batch/s, acc=0.917, loss=0.459]\n",
      "train epoch 5: 100%|██████████| 29/29 [00:01<00:00, 23.46batch/s, loss=0.0952]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.21batch/s, acc=0.926, loss=0.579]\n",
      "train epoch 6: 100%|██████████| 29/29 [00:01<00:00, 23.89batch/s, loss=0.157] \n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.32batch/s, acc=0.92, loss=0.301] \n",
      "train epoch 7: 100%|██████████| 29/29 [00:01<00:00, 23.84batch/s, loss=0.0653]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.32batch/s, acc=0.93, loss=0.274] \n",
      "train epoch 8: 100%|██████████| 29/29 [00:01<00:00, 23.75batch/s, loss=0.0972]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.12batch/s, acc=0.928, loss=0.488]\n",
      "train epoch 9: 100%|██████████| 29/29 [00:01<00:00, 23.51batch/s, loss=0.0979]\n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 24.21batch/s, acc=0.932, loss=0.219]\n",
      "train epoch 10: 100%|██████████| 29/29 [00:01<00:00, 23.27batch/s, loss=0.138] \n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 22.49batch/s, acc=0.93, loss=0.338] \n",
      "eval: 100%|██████████| 8/8 [00:00<00:00, 22.82batch/s, acc=0.93, loss=0.216] \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:30:55.038098Z",
     "start_time": "2024-12-14T09:30:44.617502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.1307], std=[0.3081]),\n",
    "    v2.Lambda(lambda img: img.view(-1))\n",
    "])\n",
    "\n",
    "train_dataset, val_dataset = get_train_test_datasets('mnist', transform)\n",
    "train_loader, val_loader = get_dataloaders([train_dataset, val_dataset], batch_size=256)\n",
    "etrain_data, etrain_label, eval_data, eval_label = [], [], [], []\n",
    "with torch.no_grad():\n",
    "    for data, label in train_loader:\n",
    "        data = data.to(device)\n",
    "        edata = model.extractor(data).to('cpu')\n",
    "        etrain_data.append(edata)\n",
    "        etrain_label.append(label)\n",
    "    for data, label in val_loader:\n",
    "        data = data.to(device)\n",
    "        edata = model.extractor(data).to('cpu')\n",
    "        eval_data.append(edata)\n",
    "        eval_label.append(label)\n",
    "etrain_data = torch.cat(etrain_data, dim=0)\n",
    "etrain_label = torch.cat(etrain_label, dim=0)\n",
    "eval_data = torch.cat(eval_data, dim=0)\n",
    "eval_label = torch.cat(eval_label, dim=0)\n",
    "train_dataset = TensorDataset(etrain_data, etrain_label)\n",
    "val_dataset = TensorDataset(eval_data, eval_label)"
   ],
   "id": "af6d486110582782",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:30:55.285210Z",
     "start_time": "2024-12-14T09:30:55.039454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retain_dataset, forget_dataset = get_retain_forget_datasets(train_dataset, 0.01)\n",
    "exact_ratios = np.asarray([0.2, 0.05, 0.1, 0.05, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "surr_ratios = np.asarray([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "exact_size = int(len(retain_dataset) / 2)\n",
    "surr_size = len(retain_dataset) - exact_size\n",
    "retain_dataset, surr_dataset = get_exact_surr_datasets(retain_dataset,\n",
    "                                                      target_size=exact_size, target_ratios=exact_ratios,\n",
    "                                                      starget_size=surr_size, starget_ratios=surr_ratios)\n",
    "train_dataset = ConcatDataset([retain_dataset, forget_dataset])\n",
    "train_loader, val_loader = get_dataloaders([train_dataset, val_dataset], batch_size=256)"
   ],
   "id": "b781bffec2b83dc9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:31:18.054574Z",
     "start_time": "2024-12-14T09:31:13.045101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = model.to('cpu') # just to clear the GPU\n",
    "model = nn.Linear(256, 10, bias=False).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(train_loader, val_loader, model, criterion, optimizer, num_epoch=10, device=device)\n",
    "evaluate(train_loader, model, criterion, device=device)"
   ],
   "id": "f28f5f1cf7afeebf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|██████████| 119/119 [00:00<00:00, 280.82batch/s, loss=0.645]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 470.23batch/s, acc=0.839, loss=0.58]\n",
      "train epoch 2: 100%|██████████| 119/119 [00:00<00:00, 356.37batch/s, loss=0.339]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 477.38batch/s, acc=0.879, loss=0.438]\n",
      "train epoch 3: 100%|██████████| 119/119 [00:00<00:00, 349.00batch/s, loss=0.336]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 469.78batch/s, acc=0.891, loss=0.347]\n",
      "train epoch 4: 100%|██████████| 119/119 [00:00<00:00, 349.05batch/s, loss=0.271]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 448.58batch/s, acc=0.901, loss=0.369]\n",
      "train epoch 5: 100%|██████████| 119/119 [00:00<00:00, 348.03batch/s, loss=0.307]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 481.34batch/s, acc=0.904, loss=0.24]\n",
      "train epoch 6: 100%|██████████| 119/119 [00:00<00:00, 267.65batch/s, loss=0.345]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 474.42batch/s, acc=0.911, loss=0.566]\n",
      "train epoch 7: 100%|██████████| 119/119 [00:00<00:00, 352.69batch/s, loss=0.19] \n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 476.42batch/s, acc=0.915, loss=0.166]\n",
      "train epoch 8: 100%|██████████| 119/119 [00:00<00:00, 355.75batch/s, loss=0.274]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 459.61batch/s, acc=0.917, loss=0.364]\n",
      "train epoch 9: 100%|██████████| 119/119 [00:00<00:00, 308.90batch/s, loss=0.234]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 336.44batch/s, acc=0.922, loss=0.239]\n",
      "train epoch 10: 100%|██████████| 119/119 [00:00<00:00, 292.69batch/s, loss=0.297]\n",
      "eval: 100%|██████████| 40/40 [00:00<00:00, 368.70batch/s, acc=0.926, loss=0.154]\n",
      "eval: 100%|██████████| 119/119 [00:00<00:00, 319.53batch/s, acc=0.933, loss=0.196]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# calc grad, calc hess, calc update, compare performances (done with this part early)\n",
    "# code to find out noise\n",
    "## upper bound of kl distance (until monday) --> show everything you have\n",
    "## rest of the assumptions"
   ],
   "id": "f41e5af25b38878e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
