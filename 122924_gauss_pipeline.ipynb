{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:46:21.057666Z",
     "start_time": "2024-12-30T01:46:18.490648Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from copy import deepcopy \n",
    "\n",
    "from src.synthetic import GaussianDataset\n",
    "from src.data import get_retain_forget_datasets, get_dataloaders\n",
    "from src.train import train, L2RegularizedCrossEntropyLoss\n",
    "from src.eval import evaluate\n",
    "from src.forget import forget, calculate_hessian, calculate_grad, calculate_update, update_model\n",
    "from src.utils import get_module_device\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:46:22.610860Z",
     "start_time": "2024-12-30T01:46:22.296070Z"
    }
   },
   "source": [
    "num_classes = 10\n",
    "num_samples = 15000\n",
    "dim = 100\n",
    "mean = np.zeros(dim)\n",
    "cov = np.eye(dim)\n",
    "## surr cov\n",
    "surr_cov = np.eye(dim)\n",
    "surr_cov[0, -1] = 0.5\n",
    "surr_cov[-1, 0] = 0.5\n",
    "##\n",
    "dataset = GaussianDataset(num_samples, num_classes, mean, cov)\n",
    "surr_dataset = dataset.create_surr(mean, surr_cov)\n",
    "train_dataset, test_dataset = get_retain_forget_datasets(dataset, 0.2)\n",
    "\n",
    "kl_distance = surr_dataset.calculate_kl_between(dataset)\n",
    "print('given kl distance:{}'.format(kl_distance))\n",
    "\n",
    "eps = 5 * (math.e ** 3)\n",
    "delta = 1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given kl distance:0.14384103622589045\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:46:23.479272Z",
     "start_time": "2024-12-30T01:46:23.446678Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = L2RegularizedCrossEntropyLoss(l2_lambda=0.1)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:46:24.427655Z",
     "start_time": "2024-12-30T01:46:24.422832Z"
    }
   },
   "source": [
    "def print_eval(model_arg):\n",
    "    print('#######################################')\n",
    "    print('train:')\n",
    "    evaluate(train_loader, model_arg, criterion, device=device)\n",
    "    print('#######################################')\n",
    "    print('#######################################')\n",
    "    print('val:')\n",
    "    evaluate(val_loader, model_arg, criterion, device=device)\n",
    "    print('#######################################')\n",
    "    print('#######################################')\n",
    "    print('retain:')\n",
    "    evaluate(retain_loader, model_arg, criterion, device=device)\n",
    "    print('#######################################')\n",
    "    print('#######################################')\n",
    "    print('forget:')\n",
    "    evaluate(forget_loader, model_arg, criterion, device=device)\n",
    "    print('#######################################')\n",
    "    print('#######################################')\n",
    "    print('surrogate:')\n",
    "    evaluate(surr_loader, model_arg, criterion, device=device)\n",
    "    print('#######################################')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:47:19.680656Z",
     "start_time": "2024-12-30T01:46:25.254588Z"
    }
   },
   "source": [
    "retain_dataset, forget_dataset = get_retain_forget_datasets(train_dataset, 0.1)\n",
    "train_loader, val_loader = get_dataloaders([train_dataset, test_dataset], batch_size=256)\n",
    "retain_loader = get_dataloaders(retain_dataset, batch_size=256)\n",
    "forget_loader = get_dataloaders(forget_dataset, batch_size=256)\n",
    "surr_loader = get_dataloaders(surr_dataset, batch_size=256)\n",
    "model = nn.Linear(dim, num_classes, bias=False).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(train_loader, val_loader, model, criterion, optimizer, num_epoch=300, device=device)\n",
    "print_eval(model)\n",
    "model = model.to('cpu')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|██████████| 47/47 [00:00<00:00, 146.06batch/s, loss=2.41]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 216.20batch/s, acc=0.114, loss=2.48]\n",
      "train epoch 2: 100%|██████████| 47/47 [00:00<00:00, 381.36batch/s, loss=2.27]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 490.43batch/s, acc=0.182, loss=2.27]\n",
      "train epoch 3: 100%|██████████| 47/47 [00:00<00:00, 391.39batch/s, loss=2.19]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 554.08batch/s, acc=0.262, loss=2.2]\n",
      "train epoch 4: 100%|██████████| 47/47 [00:00<00:00, 390.45batch/s, loss=2.15]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 486.65batch/s, acc=0.325, loss=2.15]\n",
      "train epoch 5: 100%|██████████| 47/47 [00:00<00:00, 177.25batch/s, loss=2.14]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 305.72batch/s, acc=0.361, loss=2.12]\n",
      "train epoch 6: 100%|██████████| 47/47 [00:00<00:00, 374.39batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 523.51batch/s, acc=0.399, loss=2.12]\n",
      "train epoch 7: 100%|██████████| 47/47 [00:00<00:00, 376.62batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 498.89batch/s, acc=0.417, loss=2.1]\n",
      "train epoch 8: 100%|██████████| 47/47 [00:00<00:00, 381.42batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 489.45batch/s, acc=0.442, loss=2.11]\n",
      "train epoch 9: 100%|██████████| 47/47 [00:00<00:00, 361.18batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 500.93batch/s, acc=0.459, loss=2.07]\n",
      "train epoch 10: 100%|██████████| 47/47 [00:00<00:00, 352.48batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 407.14batch/s, acc=0.473, loss=2.07]\n",
      "train epoch 11: 100%|██████████| 47/47 [00:00<00:00, 348.34batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 458.61batch/s, acc=0.495, loss=2.07]\n",
      "train epoch 12: 100%|██████████| 47/47 [00:00<00:00, 332.89batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 339.17batch/s, acc=0.502, loss=2.07]\n",
      "train epoch 13: 100%|██████████| 47/47 [00:00<00:00, 339.16batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 323.33batch/s, acc=0.518, loss=2.05]\n",
      "train epoch 14: 100%|██████████| 47/47 [00:00<00:00, 339.08batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.93batch/s, acc=0.527, loss=2.05]\n",
      "train epoch 15: 100%|██████████| 47/47 [00:00<00:00, 333.85batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 366.81batch/s, acc=0.536, loss=2.07]\n",
      "train epoch 16: 100%|██████████| 47/47 [00:00<00:00, 338.14batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 365.91batch/s, acc=0.544, loss=2.05]\n",
      "train epoch 17: 100%|██████████| 47/47 [00:00<00:00, 345.35batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.60batch/s, acc=0.538, loss=2.05]\n",
      "train epoch 18: 100%|██████████| 47/47 [00:00<00:00, 338.23batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 495.57batch/s, acc=0.548, loss=2.05]\n",
      "train epoch 19: 100%|██████████| 47/47 [00:00<00:00, 342.39batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 433.19batch/s, acc=0.549, loss=2.04]\n",
      "train epoch 20: 100%|██████████| 47/47 [00:00<00:00, 339.57batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 407.17batch/s, acc=0.551, loss=2.06]\n",
      "train epoch 21: 100%|██████████| 47/47 [00:00<00:00, 318.40batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.48batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 22: 100%|██████████| 47/47 [00:00<00:00, 323.59batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 374.43batch/s, acc=0.561, loss=2.02]\n",
      "train epoch 23: 100%|██████████| 47/47 [00:00<00:00, 326.15batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 391.27batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 24: 100%|██████████| 47/47 [00:00<00:00, 183.12batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.57batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 25: 100%|██████████| 47/47 [00:00<00:00, 323.57batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 379.61batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 26: 100%|██████████| 47/47 [00:00<00:00, 322.18batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.07batch/s, acc=0.558, loss=2.08]\n",
      "train epoch 27: 100%|██████████| 47/47 [00:00<00:00, 326.10batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 390.65batch/s, acc=0.56, loss=2.02]\n",
      "train epoch 28: 100%|██████████| 47/47 [00:00<00:00, 337.37batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 410.36batch/s, acc=0.563, loss=2.07]\n",
      "train epoch 29: 100%|██████████| 47/47 [00:00<00:00, 333.85batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 382.13batch/s, acc=0.562, loss=2.07]\n",
      "train epoch 30: 100%|██████████| 47/47 [00:00<00:00, 324.41batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 389.05batch/s, acc=0.565, loss=2.06]\n",
      "train epoch 31: 100%|██████████| 47/47 [00:00<00:00, 332.07batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.92batch/s, acc=0.557, loss=2.07]\n",
      "train epoch 32: 100%|██████████| 47/47 [00:00<00:00, 340.30batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 408.05batch/s, acc=0.564, loss=2.02]\n",
      "train epoch 33: 100%|██████████| 47/47 [00:00<00:00, 330.91batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 388.57batch/s, acc=0.56, loss=2.04]\n",
      "train epoch 34: 100%|██████████| 47/47 [00:00<00:00, 331.79batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 397.23batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 35: 100%|██████████| 47/47 [00:00<00:00, 326.00batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 410.24batch/s, acc=0.563, loss=2.04]\n",
      "train epoch 36: 100%|██████████| 47/47 [00:00<00:00, 327.74batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 394.32batch/s, acc=0.564, loss=2.07]\n",
      "train epoch 37: 100%|██████████| 47/47 [00:00<00:00, 324.20batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 401.80batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 38: 100%|██████████| 47/47 [00:00<00:00, 339.47batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 372.35batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 39: 100%|██████████| 47/47 [00:00<00:00, 341.62batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 413.74batch/s, acc=0.566, loss=2.03]\n",
      "train epoch 40: 100%|██████████| 47/47 [00:00<00:00, 324.20batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.24batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 41: 100%|██████████| 47/47 [00:00<00:00, 323.65batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 389.68batch/s, acc=0.556, loss=2.02]\n",
      "train epoch 42: 100%|██████████| 47/47 [00:00<00:00, 329.64batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.82batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 43: 100%|██████████| 47/47 [00:00<00:00, 317.79batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 410.92batch/s, acc=0.566, loss=2.05]\n",
      "train epoch 44: 100%|██████████| 47/47 [00:00<00:00, 187.65batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.64batch/s, acc=0.561, loss=2.05]\n",
      "train epoch 45: 100%|██████████| 47/47 [00:00<00:00, 336.36batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.65batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 46: 100%|██████████| 47/47 [00:00<00:00, 325.24batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 417.47batch/s, acc=0.563, loss=2.05]\n",
      "train epoch 47: 100%|██████████| 47/47 [00:00<00:00, 329.05batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 380.46batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 48: 100%|██████████| 47/47 [00:00<00:00, 323.93batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 377.34batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 49: 100%|██████████| 47/47 [00:00<00:00, 334.66batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 361.37batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 50: 100%|██████████| 47/47 [00:00<00:00, 332.68batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 391.77batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 51: 100%|██████████| 47/47 [00:00<00:00, 329.70batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 371.42batch/s, acc=0.565, loss=2.05]\n",
      "train epoch 52: 100%|██████████| 47/47 [00:00<00:00, 336.03batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 378.75batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 53: 100%|██████████| 47/47 [00:00<00:00, 337.21batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 434.33batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 54: 100%|██████████| 47/47 [00:00<00:00, 335.87batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 403.12batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 55: 100%|██████████| 47/47 [00:00<00:00, 339.75batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.47batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 56: 100%|██████████| 47/47 [00:00<00:00, 346.69batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.76batch/s, acc=0.554, loss=2.07]\n",
      "train epoch 57: 100%|██████████| 47/47 [00:00<00:00, 327.69batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 389.53batch/s, acc=0.56, loss=2.03]\n",
      "train epoch 58: 100%|██████████| 47/47 [00:00<00:00, 341.12batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.40batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 59: 100%|██████████| 47/47 [00:00<00:00, 326.41batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 364.76batch/s, acc=0.563, loss=2.03]\n",
      "train epoch 60: 100%|██████████| 47/47 [00:00<00:00, 331.95batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 375.59batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 61: 100%|██████████| 47/47 [00:00<00:00, 335.05batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.21batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 62: 100%|██████████| 47/47 [00:00<00:00, 342.54batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 373.04batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 63: 100%|██████████| 47/47 [00:00<00:00, 331.02batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 85.95batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 64: 100%|██████████| 47/47 [00:00<00:00, 332.95batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.33batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 65: 100%|██████████| 47/47 [00:00<00:00, 320.65batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.81batch/s, acc=0.565, loss=2.07]\n",
      "train epoch 66: 100%|██████████| 47/47 [00:00<00:00, 330.39batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.77batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 67: 100%|██████████| 47/47 [00:00<00:00, 307.23batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.46batch/s, acc=0.555, loss=2.08]\n",
      "train epoch 68: 100%|██████████| 47/47 [00:00<00:00, 314.74batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.56batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 69: 100%|██████████| 47/47 [00:00<00:00, 327.18batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.28batch/s, acc=0.553, loss=2.05]\n",
      "train epoch 70: 100%|██████████| 47/47 [00:00<00:00, 328.08batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 308.15batch/s, acc=0.563, loss=2.06]\n",
      "train epoch 71: 100%|██████████| 47/47 [00:00<00:00, 308.09batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.75batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 72: 100%|██████████| 47/47 [00:00<00:00, 327.16batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 369.48batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 73: 100%|██████████| 47/47 [00:00<00:00, 323.24batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.73batch/s, acc=0.567, loss=2.04]\n",
      "train epoch 74: 100%|██████████| 47/47 [00:00<00:00, 307.74batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 361.56batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 75: 100%|██████████| 47/47 [00:00<00:00, 329.12batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.33batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 76: 100%|██████████| 47/47 [00:00<00:00, 323.16batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 433.50batch/s, acc=0.561, loss=2.07]\n",
      "train epoch 77: 100%|██████████| 47/47 [00:00<00:00, 340.50batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.56batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 78: 100%|██████████| 47/47 [00:00<00:00, 336.63batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.43batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 79: 100%|██████████| 47/47 [00:00<00:00, 338.91batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 383.22batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 80: 100%|██████████| 47/47 [00:00<00:00, 344.77batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 455.16batch/s, acc=0.562, loss=2.03]\n",
      "train epoch 81: 100%|██████████| 47/47 [00:00<00:00, 352.79batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.09batch/s, acc=0.563, loss=2.05]\n",
      "train epoch 82: 100%|██████████| 47/47 [00:00<00:00, 340.76batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.09batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 83: 100%|██████████| 47/47 [00:00<00:00, 194.65batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 532.25batch/s, acc=0.558, loss=2.03]\n",
      "train epoch 84: 100%|██████████| 47/47 [00:00<00:00, 360.94batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 444.35batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 85: 100%|██████████| 47/47 [00:00<00:00, 354.76batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 362.35batch/s, acc=0.564, loss=2.05]\n",
      "train epoch 86: 100%|██████████| 47/47 [00:00<00:00, 351.76batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 382.72batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 87: 100%|██████████| 47/47 [00:00<00:00, 353.13batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.25batch/s, acc=0.565, loss=2.03]\n",
      "train epoch 88: 100%|██████████| 47/47 [00:00<00:00, 347.96batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.70batch/s, acc=0.562, loss=2.04]\n",
      "train epoch 89: 100%|██████████| 47/47 [00:00<00:00, 349.68batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 437.72batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 90: 100%|██████████| 47/47 [00:00<00:00, 345.53batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.65batch/s, acc=0.561, loss=2.07]\n",
      "train epoch 91: 100%|██████████| 47/47 [00:00<00:00, 351.72batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 455.08batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 92: 100%|██████████| 47/47 [00:00<00:00, 349.37batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 394.33batch/s, acc=0.558, loss=2.08]\n",
      "train epoch 93: 100%|██████████| 47/47 [00:00<00:00, 341.75batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.68batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 94: 100%|██████████| 47/47 [00:00<00:00, 347.58batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.91batch/s, acc=0.564, loss=2.03]\n",
      "train epoch 95: 100%|██████████| 47/47 [00:00<00:00, 351.15batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 368.43batch/s, acc=0.558, loss=2.08]\n",
      "train epoch 96: 100%|██████████| 47/47 [00:00<00:00, 348.31batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 354.82batch/s, acc=0.556, loss=2.03]\n",
      "train epoch 97: 100%|██████████| 47/47 [00:00<00:00, 329.54batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.19batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 98: 100%|██████████| 47/47 [00:00<00:00, 351.42batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 438.65batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 99: 100%|██████████| 47/47 [00:00<00:00, 339.14batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 398.75batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 100: 100%|██████████| 47/47 [00:00<00:00, 347.91batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 371.78batch/s, acc=0.561, loss=2.08]\n",
      "train epoch 101: 100%|██████████| 47/47 [00:00<00:00, 357.45batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 422.10batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 102: 100%|██████████| 47/47 [00:00<00:00, 351.35batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 397.21batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 103: 100%|██████████| 47/47 [00:00<00:00, 194.30batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 452.70batch/s, acc=0.56, loss=2.03]\n",
      "train epoch 104: 100%|██████████| 47/47 [00:00<00:00, 351.34batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 398.24batch/s, acc=0.562, loss=2.04]\n",
      "train epoch 105: 100%|██████████| 47/47 [00:00<00:00, 361.95batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 452.46batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 106: 100%|██████████| 47/47 [00:00<00:00, 354.96batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 452.61batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 107: 100%|██████████| 47/47 [00:00<00:00, 352.80batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 457.69batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 108: 100%|██████████| 47/47 [00:00<00:00, 353.00batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.37batch/s, acc=0.561, loss=2.09]\n",
      "train epoch 109: 100%|██████████| 47/47 [00:00<00:00, 364.52batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 411.49batch/s, acc=0.557, loss=2.08]\n",
      "train epoch 110: 100%|██████████| 47/47 [00:00<00:00, 340.36batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 448.01batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 111: 100%|██████████| 47/47 [00:00<00:00, 329.49batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 423.70batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 112: 100%|██████████| 47/47 [00:00<00:00, 341.67batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 380.00batch/s, acc=0.557, loss=2.09]\n",
      "train epoch 113: 100%|██████████| 47/47 [00:00<00:00, 346.21batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 486.07batch/s, acc=0.565, loss=2.03]\n",
      "train epoch 114: 100%|██████████| 47/47 [00:00<00:00, 357.79batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 351.45batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 115: 100%|██████████| 47/47 [00:00<00:00, 358.05batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.09batch/s, acc=0.56, loss=2.04]\n",
      "train epoch 116: 100%|██████████| 47/47 [00:00<00:00, 345.62batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 363.59batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 117: 100%|██████████| 47/47 [00:00<00:00, 356.14batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 453.06batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 118: 100%|██████████| 47/47 [00:00<00:00, 345.64batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.69batch/s, acc=0.557, loss=2.04]\n",
      "train epoch 119: 100%|██████████| 47/47 [00:00<00:00, 352.91batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 450.22batch/s, acc=0.562, loss=2.04]\n",
      "train epoch 120: 100%|██████████| 47/47 [00:00<00:00, 322.45batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 415.95batch/s, acc=0.56, loss=2.08]\n",
      "train epoch 121: 100%|██████████| 47/47 [00:00<00:00, 346.68batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.20batch/s, acc=0.557, loss=2.07]\n",
      "train epoch 122: 100%|██████████| 47/47 [00:00<00:00, 186.68batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 398.81batch/s, acc=0.564, loss=2.05]\n",
      "train epoch 123: 100%|██████████| 47/47 [00:00<00:00, 336.43batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 333.71batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 124: 100%|██████████| 47/47 [00:00<00:00, 333.01batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.05batch/s, acc=0.56, loss=2.08]\n",
      "train epoch 125: 100%|██████████| 47/47 [00:00<00:00, 346.36batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.89batch/s, acc=0.562, loss=2.01]\n",
      "train epoch 126: 100%|██████████| 47/47 [00:00<00:00, 350.77batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 373.60batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 127: 100%|██████████| 47/47 [00:00<00:00, 364.85batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 440.19batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 128: 100%|██████████| 47/47 [00:00<00:00, 349.83batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 307.99batch/s, acc=0.559, loss=2.03]\n",
      "train epoch 129: 100%|██████████| 47/47 [00:00<00:00, 332.25batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 375.15batch/s, acc=0.564, loss=2.05]\n",
      "train epoch 130: 100%|██████████| 47/47 [00:00<00:00, 333.44batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.11batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 131: 100%|██████████| 47/47 [00:00<00:00, 337.04batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 339.96batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 132: 100%|██████████| 47/47 [00:00<00:00, 316.59batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.22batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 133: 100%|██████████| 47/47 [00:00<00:00, 312.70batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 390.92batch/s, acc=0.557, loss=2.07]\n",
      "train epoch 134: 100%|██████████| 47/47 [00:00<00:00, 325.61batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.82batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 135: 100%|██████████| 47/47 [00:00<00:00, 333.65batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 417.35batch/s, acc=0.565, loss=2.02]\n",
      "train epoch 136: 100%|██████████| 47/47 [00:00<00:00, 324.47batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 348.66batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 137: 100%|██████████| 47/47 [00:00<00:00, 324.22batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 422.22batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 138: 100%|██████████| 47/47 [00:00<00:00, 340.40batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.78batch/s, acc=0.564, loss=2.06]\n",
      "train epoch 139: 100%|██████████| 47/47 [00:00<00:00, 330.75batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 361.68batch/s, acc=0.564, loss=2.07]\n",
      "train epoch 140: 100%|██████████| 47/47 [00:00<00:00, 319.49batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 363.47batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 141: 100%|██████████| 47/47 [00:00<00:00, 337.44batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 397.90batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 142: 100%|██████████| 47/47 [00:00<00:00, 183.80batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 424.07batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 143: 100%|██████████| 47/47 [00:00<00:00, 326.25batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.88batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 144: 100%|██████████| 47/47 [00:00<00:00, 329.07batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.41batch/s, acc=0.564, loss=2.05]\n",
      "train epoch 145: 100%|██████████| 47/47 [00:00<00:00, 345.65batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 409.84batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 146: 100%|██████████| 47/47 [00:00<00:00, 340.18batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.43batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 147: 100%|██████████| 47/47 [00:00<00:00, 325.61batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 446.24batch/s, acc=0.555, loss=2.07]\n",
      "train epoch 148: 100%|██████████| 47/47 [00:00<00:00, 322.70batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 416.68batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 149: 100%|██████████| 47/47 [00:00<00:00, 317.25batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.81batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 150: 100%|██████████| 47/47 [00:00<00:00, 351.58batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 372.23batch/s, acc=0.563, loss=2.04]\n",
      "train epoch 151: 100%|██████████| 47/47 [00:00<00:00, 345.24batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 469.77batch/s, acc=0.568, loss=2.05]\n",
      "train epoch 152: 100%|██████████| 47/47 [00:00<00:00, 355.10batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 389.35batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 153: 100%|██████████| 47/47 [00:00<00:00, 358.34batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 459.54batch/s, acc=0.553, loss=2.02]\n",
      "train epoch 154: 100%|██████████| 47/47 [00:00<00:00, 345.55batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.79batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 155: 100%|██████████| 47/47 [00:00<00:00, 348.28batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.79batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 156: 100%|██████████| 47/47 [00:00<00:00, 351.75batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 375.48batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 157: 100%|██████████| 47/47 [00:00<00:00, 343.82batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 446.30batch/s, acc=0.564, loss=2.06]\n",
      "train epoch 158: 100%|██████████| 47/47 [00:00<00:00, 341.34batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 452.10batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 159: 100%|██████████| 47/47 [00:00<00:00, 363.66batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 387.57batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 160: 100%|██████████| 47/47 [00:00<00:00, 349.54batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 463.37batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 161: 100%|██████████| 47/47 [00:00<00:00, 362.20batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 83.56batch/s, acc=0.555, loss=2.03]\n",
      "train epoch 162: 100%|██████████| 47/47 [00:00<00:00, 358.47batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 373.24batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 163: 100%|██████████| 47/47 [00:00<00:00, 343.57batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 454.63batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 164: 100%|██████████| 47/47 [00:00<00:00, 346.31batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 383.97batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 165: 100%|██████████| 47/47 [00:00<00:00, 352.10batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 421.07batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 166: 100%|██████████| 47/47 [00:00<00:00, 356.60batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.51batch/s, acc=0.56, loss=2.03]\n",
      "train epoch 167: 100%|██████████| 47/47 [00:00<00:00, 354.60batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 398.77batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 168: 100%|██████████| 47/47 [00:00<00:00, 351.58batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 379.15batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 169: 100%|██████████| 47/47 [00:00<00:00, 348.74batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 379.02batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 170: 100%|██████████| 47/47 [00:00<00:00, 358.32batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.75batch/s, acc=0.564, loss=2.04]\n",
      "train epoch 171: 100%|██████████| 47/47 [00:00<00:00, 337.80batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 326.71batch/s, acc=0.56, loss=2.01]\n",
      "train epoch 172: 100%|██████████| 47/47 [00:00<00:00, 344.75batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.91batch/s, acc=0.562, loss=2.09]\n",
      "train epoch 173: 100%|██████████| 47/47 [00:00<00:00, 356.29batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.92batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 174: 100%|██████████| 47/47 [00:00<00:00, 358.61batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.59batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 175: 100%|██████████| 47/47 [00:00<00:00, 326.97batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.94batch/s, acc=0.564, loss=2.02]\n",
      "train epoch 176: 100%|██████████| 47/47 [00:00<00:00, 312.35batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 350.79batch/s, acc=0.562, loss=2.04]\n",
      "train epoch 177: 100%|██████████| 47/47 [00:00<00:00, 312.29batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 334.12batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 178: 100%|██████████| 47/47 [00:00<00:00, 319.38batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.63batch/s, acc=0.562, loss=2.04]\n",
      "train epoch 179: 100%|██████████| 47/47 [00:00<00:00, 318.04batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 413.11batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 180: 100%|██████████| 47/47 [00:00<00:00, 315.65batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.84batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 181: 100%|██████████| 47/47 [00:00<00:00, 188.82batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 466.05batch/s, acc=0.561, loss=2.08]\n",
      "train epoch 182: 100%|██████████| 47/47 [00:00<00:00, 341.20batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 404.83batch/s, acc=0.56, loss=2.04]\n",
      "train epoch 183: 100%|██████████| 47/47 [00:00<00:00, 324.22batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 417.00batch/s, acc=0.56, loss=2.02]\n",
      "train epoch 184: 100%|██████████| 47/47 [00:00<00:00, 322.33batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.14batch/s, acc=0.564, loss=2.08]\n",
      "train epoch 185: 100%|██████████| 47/47 [00:00<00:00, 320.19batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 378.31batch/s, acc=0.56, loss=2.08]\n",
      "train epoch 186: 100%|██████████| 47/47 [00:00<00:00, 334.63batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.64batch/s, acc=0.561, loss=2.07]\n",
      "train epoch 187: 100%|██████████| 47/47 [00:00<00:00, 317.92batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 390.85batch/s, acc=0.56, loss=2.02]\n",
      "train epoch 188: 100%|██████████| 47/47 [00:00<00:00, 317.85batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 346.68batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 189: 100%|██████████| 47/47 [00:00<00:00, 308.50batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 370.46batch/s, acc=0.561, loss=2.08]\n",
      "train epoch 190: 100%|██████████| 47/47 [00:00<00:00, 303.15batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.42batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 191: 100%|██████████| 47/47 [00:00<00:00, 323.31batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 436.68batch/s, acc=0.564, loss=2.04]\n",
      "train epoch 192: 100%|██████████| 47/47 [00:00<00:00, 318.73batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.04batch/s, acc=0.565, loss=2.05]\n",
      "train epoch 193: 100%|██████████| 47/47 [00:00<00:00, 338.93batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.81batch/s, acc=0.557, loss=2.02]\n",
      "train epoch 194: 100%|██████████| 47/47 [00:00<00:00, 316.24batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.13batch/s, acc=0.564, loss=2.04]\n",
      "train epoch 195: 100%|██████████| 47/47 [00:00<00:00, 341.68batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 316.76batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 196: 100%|██████████| 47/47 [00:00<00:00, 328.64batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.66batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 197: 100%|██████████| 47/47 [00:00<00:00, 348.22batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 422.83batch/s, acc=0.564, loss=2.05]\n",
      "train epoch 198: 100%|██████████| 47/47 [00:00<00:00, 348.04batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 375.71batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 199: 100%|██████████| 47/47 [00:00<00:00, 342.33batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.55batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 200: 100%|██████████| 47/47 [00:00<00:00, 335.82batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 435.02batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 201: 100%|██████████| 47/47 [00:00<00:00, 181.19batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.76batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 202: 100%|██████████| 47/47 [00:00<00:00, 334.53batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 352.75batch/s, acc=0.565, loss=2.05]\n",
      "train epoch 203: 100%|██████████| 47/47 [00:00<00:00, 338.65batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.96batch/s, acc=0.553, loss=2.06]\n",
      "train epoch 204: 100%|██████████| 47/47 [00:00<00:00, 315.51batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 312.35batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 205: 100%|██████████| 47/47 [00:00<00:00, 310.45batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 317.62batch/s, acc=0.558, loss=2.03]\n",
      "train epoch 206: 100%|██████████| 47/47 [00:00<00:00, 329.54batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 355.50batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 207: 100%|██████████| 47/47 [00:00<00:00, 336.15batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.42batch/s, acc=0.562, loss=2.03]\n",
      "train epoch 208: 100%|██████████| 47/47 [00:00<00:00, 318.81batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 340.77batch/s, acc=0.566, loss=2.03]\n",
      "train epoch 209: 100%|██████████| 47/47 [00:00<00:00, 337.59batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 382.79batch/s, acc=0.568, loss=2.05]\n",
      "train epoch 210: 100%|██████████| 47/47 [00:00<00:00, 331.04batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 442.70batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 211: 100%|██████████| 47/47 [00:00<00:00, 324.51batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.11batch/s, acc=0.558, loss=2.02]\n",
      "train epoch 212: 100%|██████████| 47/47 [00:00<00:00, 318.87batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 343.24batch/s, acc=0.566, loss=2.06]\n",
      "train epoch 213: 100%|██████████| 47/47 [00:00<00:00, 317.05batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.85batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 214: 100%|██████████| 47/47 [00:00<00:00, 332.40batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.71batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 215: 100%|██████████| 47/47 [00:00<00:00, 318.33batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 351.68batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 216: 100%|██████████| 47/47 [00:00<00:00, 312.51batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 381.61batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 217: 100%|██████████| 47/47 [00:00<00:00, 324.67batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.64batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 218: 100%|██████████| 47/47 [00:00<00:00, 304.23batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.10batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 219: 100%|██████████| 47/47 [00:00<00:00, 311.29batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 347.95batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 220: 100%|██████████| 47/47 [00:00<00:00, 180.61batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 421.88batch/s, acc=0.563, loss=2.07]\n",
      "train epoch 221: 100%|██████████| 47/47 [00:00<00:00, 318.13batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 378.31batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 222: 100%|██████████| 47/47 [00:00<00:00, 327.34batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.47batch/s, acc=0.557, loss=2.03]\n",
      "train epoch 223: 100%|██████████| 47/47 [00:00<00:00, 310.95batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 362.12batch/s, acc=0.555, loss=2.08]\n",
      "train epoch 224: 100%|██████████| 47/47 [00:00<00:00, 318.50batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.94batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 225: 100%|██████████| 47/47 [00:00<00:00, 333.55batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 374.89batch/s, acc=0.553, loss=2.03]\n",
      "train epoch 226: 100%|██████████| 47/47 [00:00<00:00, 323.63batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 342.25batch/s, acc=0.557, loss=2.04]\n",
      "train epoch 227: 100%|██████████| 47/47 [00:00<00:00, 331.86batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 368.19batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 228: 100%|██████████| 47/47 [00:00<00:00, 329.31batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 380.30batch/s, acc=0.561, loss=2.05]\n",
      "train epoch 229: 100%|██████████| 47/47 [00:00<00:00, 316.54batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 321.80batch/s, acc=0.563, loss=2.06]\n",
      "train epoch 230: 100%|██████████| 47/47 [00:00<00:00, 309.84batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 388.13batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 231: 100%|██████████| 47/47 [00:00<00:00, 306.03batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.68batch/s, acc=0.557, loss=2.07]\n",
      "train epoch 232: 100%|██████████| 47/47 [00:00<00:00, 311.34batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 325.70batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 233: 100%|██████████| 47/47 [00:00<00:00, 326.69batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 355.10batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 234: 100%|██████████| 47/47 [00:00<00:00, 330.20batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.22batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 235: 100%|██████████| 47/47 [00:00<00:00, 318.68batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.28batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 236: 100%|██████████| 47/47 [00:00<00:00, 343.54batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 347.47batch/s, acc=0.565, loss=2.03]\n",
      "train epoch 237: 100%|██████████| 47/47 [00:00<00:00, 335.64batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 348.74batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 238: 100%|██████████| 47/47 [00:00<00:00, 332.74batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 380.04batch/s, acc=0.564, loss=2.02]\n",
      "train epoch 239: 100%|██████████| 47/47 [00:00<00:00, 328.72batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 388.81batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 240: 100%|██████████| 47/47 [00:00<00:00, 187.85batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 397.29batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 241: 100%|██████████| 47/47 [00:00<00:00, 323.56batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 394.72batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 242: 100%|██████████| 47/47 [00:00<00:00, 343.14batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 375.14batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 243: 100%|██████████| 47/47 [00:00<00:00, 338.64batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.52batch/s, acc=0.558, loss=2.03]\n",
      "train epoch 244: 100%|██████████| 47/47 [00:00<00:00, 340.78batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 459.21batch/s, acc=0.561, loss=2.05]\n",
      "train epoch 245: 100%|██████████| 47/47 [00:00<00:00, 339.02batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 401.78batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 246: 100%|██████████| 47/47 [00:00<00:00, 349.70batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 407.89batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 247: 100%|██████████| 47/47 [00:00<00:00, 335.04batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 370.07batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 248: 100%|██████████| 47/47 [00:00<00:00, 326.05batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 354.64batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 249: 100%|██████████| 47/47 [00:00<00:00, 330.39batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.93batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 250: 100%|██████████| 47/47 [00:00<00:00, 339.20batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.12batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 251: 100%|██████████| 47/47 [00:00<00:00, 341.17batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 354.31batch/s, acc=0.554, loss=2.02]\n",
      "train epoch 252: 100%|██████████| 47/47 [00:00<00:00, 352.96batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.32batch/s, acc=0.567, loss=2.06]\n",
      "train epoch 253: 100%|██████████| 47/47 [00:00<00:00, 349.91batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 446.87batch/s, acc=0.568, loss=2.04]\n",
      "train epoch 254: 100%|██████████| 47/47 [00:00<00:00, 332.25batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 420.96batch/s, acc=0.561, loss=2.03]\n",
      "train epoch 255: 100%|██████████| 47/47 [00:00<00:00, 362.28batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 475.27batch/s, acc=0.559, loss=2.03]\n",
      "train epoch 256: 100%|██████████| 47/47 [00:00<00:00, 354.40batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 433.42batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 257: 100%|██████████| 47/47 [00:00<00:00, 329.95batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 445.14batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 258: 100%|██████████| 47/47 [00:00<00:00, 332.59batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.60batch/s, acc=0.557, loss=2.03]\n",
      "train epoch 259: 100%|██████████| 47/47 [00:00<00:00, 336.74batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 82.40batch/s, acc=0.561, loss=2.07]\n",
      "train epoch 260: 100%|██████████| 47/47 [00:00<00:00, 344.57batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 426.07batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 261: 100%|██████████| 47/47 [00:00<00:00, 334.10batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 388.69batch/s, acc=0.564, loss=2.03]\n",
      "train epoch 262: 100%|██████████| 47/47 [00:00<00:00, 313.64batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 411.86batch/s, acc=0.558, loss=2.02]\n",
      "train epoch 263: 100%|██████████| 47/47 [00:00<00:00, 360.69batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 431.52batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 264: 100%|██████████| 47/47 [00:00<00:00, 345.12batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.89batch/s, acc=0.553, loss=2.05]\n",
      "train epoch 265: 100%|██████████| 47/47 [00:00<00:00, 349.05batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 363.68batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 266: 100%|██████████| 47/47 [00:00<00:00, 346.58batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.90batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 267: 100%|██████████| 47/47 [00:00<00:00, 353.99batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 423.37batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 268: 100%|██████████| 47/47 [00:00<00:00, 342.57batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 314.89batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 269: 100%|██████████| 47/47 [00:00<00:00, 340.25batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 432.96batch/s, acc=0.565, loss=2.03]\n",
      "train epoch 270: 100%|██████████| 47/47 [00:00<00:00, 350.87batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 355.16batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 271: 100%|██████████| 47/47 [00:00<00:00, 336.93batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 429.37batch/s, acc=0.565, loss=2.09]\n",
      "train epoch 272: 100%|██████████| 47/47 [00:00<00:00, 333.32batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 398.57batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 273: 100%|██████████| 47/47 [00:00<00:00, 336.42batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 469.77batch/s, acc=0.56, loss=2.04]\n",
      "train epoch 274: 100%|██████████| 47/47 [00:00<00:00, 331.13batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 332.27batch/s, acc=0.559, loss=2.03]\n",
      "train epoch 275: 100%|██████████| 47/47 [00:00<00:00, 331.70batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 407.24batch/s, acc=0.56, loss=2.03]\n",
      "train epoch 276: 100%|██████████| 47/47 [00:00<00:00, 343.38batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.74batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 277: 100%|██████████| 47/47 [00:00<00:00, 352.19batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 373.67batch/s, acc=0.551, loss=2.07]\n",
      "train epoch 278: 100%|██████████| 47/47 [00:00<00:00, 350.86batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 434.94batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 279: 100%|██████████| 47/47 [00:00<00:00, 199.67batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.98batch/s, acc=0.557, loss=2.03]\n",
      "train epoch 280: 100%|██████████| 47/47 [00:00<00:00, 351.10batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.87batch/s, acc=0.564, loss=2.05]\n",
      "train epoch 281: 100%|██████████| 47/47 [00:00<00:00, 362.11batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 459.11batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 282: 100%|██████████| 47/47 [00:00<00:00, 346.02batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.48batch/s, acc=0.557, loss=2.08]\n",
      "train epoch 283: 100%|██████████| 47/47 [00:00<00:00, 319.50batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 446.50batch/s, acc=0.56, loss=2.01]\n",
      "train epoch 284: 100%|██████████| 47/47 [00:00<00:00, 357.65batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.70batch/s, acc=0.563, loss=2.04]\n",
      "train epoch 285: 100%|██████████| 47/47 [00:00<00:00, 347.12batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.06batch/s, acc=0.565, loss=2.04]\n",
      "train epoch 286: 100%|██████████| 47/47 [00:00<00:00, 336.03batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 381.05batch/s, acc=0.557, loss=2.08]\n",
      "train epoch 287: 100%|██████████| 47/47 [00:00<00:00, 335.72batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 351.65batch/s, acc=0.559, loss=2.03]\n",
      "train epoch 288: 100%|██████████| 47/47 [00:00<00:00, 354.18batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 450.96batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 289: 100%|██████████| 47/47 [00:00<00:00, 343.01batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 467.28batch/s, acc=0.564, loss=2.06]\n",
      "train epoch 290: 100%|██████████| 47/47 [00:00<00:00, 341.85batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 394.80batch/s, acc=0.566, loss=2.05]\n",
      "train epoch 291: 100%|██████████| 47/47 [00:00<00:00, 342.20batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 338.87batch/s, acc=0.567, loss=2.06]\n",
      "train epoch 292: 100%|██████████| 47/47 [00:00<00:00, 344.30batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 365.93batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 293: 100%|██████████| 47/47 [00:00<00:00, 356.52batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 404.35batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 294: 100%|██████████| 47/47 [00:00<00:00, 330.84batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 386.57batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 295: 100%|██████████| 47/47 [00:00<00:00, 320.25batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.83batch/s, acc=0.563, loss=2.07]\n",
      "train epoch 296: 100%|██████████| 47/47 [00:00<00:00, 327.90batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.40batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 297: 100%|██████████| 47/47 [00:00<00:00, 332.88batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.82batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 298: 100%|██████████| 47/47 [00:00<00:00, 326.86batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 351.10batch/s, acc=0.563, loss=2.07]\n",
      "train epoch 299: 100%|██████████| 47/47 [00:00<00:00, 184.99batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.94batch/s, acc=0.565, loss=2.05]\n",
      "train epoch 300: 100%|██████████| 47/47 [00:00<00:00, 335.04batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.16batch/s, acc=0.559, loss=2.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 47/47 [00:00<00:00, 389.76batch/s, acc=0.644, loss=2.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 12/12 [00:00<00:00, 372.98batch/s, acc=0.559, loss=2.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "retain:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 43/43 [00:00<00:00, 450.96batch/s, acc=0.643, loss=2.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "forget:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 5/5 [00:00<00:00, 479.40batch/s, acc=0.654, loss=2.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "surrogate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 59/59 [00:00<00:00, 457.04batch/s, acc=0.589, loss=2.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:49:14.899047Z",
     "start_time": "2024-12-30T01:48:29.867058Z"
    }
   },
   "source": [
    "# retrain from scratch\n",
    "rmodel = nn.Linear(dim, num_classes, bias=False).to(device)\n",
    "optimizer = torch.optim.Adam(rmodel.parameters(), lr=0.001)\n",
    "train(retain_loader, val_loader, rmodel, criterion, optimizer, num_epoch=300, device=device)\n",
    "\n",
    "print_eval(rmodel)\n",
    "rmodel = rmodel.to('cpu')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|██████████| 43/43 [00:00<00:00, 246.61batch/s, loss=2.42]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.87batch/s, acc=0.153, loss=2.44]\n",
      "train epoch 2: 100%|██████████| 43/43 [00:00<00:00, 408.18batch/s, loss=2.26]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 440.62batch/s, acc=0.23, loss=2.25]\n",
      "train epoch 3: 100%|██████████| 43/43 [00:00<00:00, 394.00batch/s, loss=2.15]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 451.46batch/s, acc=0.309, loss=2.17]\n",
      "train epoch 4: 100%|██████████| 43/43 [00:00<00:00, 382.88batch/s, loss=2.15]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 493.24batch/s, acc=0.368, loss=2.13]\n",
      "train epoch 5: 100%|██████████| 43/43 [00:00<00:00, 385.68batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 471.18batch/s, acc=0.414, loss=2.11]\n",
      "train epoch 6: 100%|██████████| 43/43 [00:00<00:00, 371.14batch/s, loss=2.1] \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 463.75batch/s, acc=0.435, loss=2.11]\n",
      "train epoch 7: 100%|██████████| 43/43 [00:00<00:00, 383.41batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 470.67batch/s, acc=0.452, loss=2.08]\n",
      "train epoch 8: 100%|██████████| 43/43 [00:00<00:00, 386.45batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 455.91batch/s, acc=0.475, loss=2.09]\n",
      "train epoch 9: 100%|██████████| 43/43 [00:00<00:00, 370.32batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 424.53batch/s, acc=0.484, loss=2.06]\n",
      "train epoch 10: 100%|██████████| 43/43 [00:00<00:00, 337.60batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 372.63batch/s, acc=0.503, loss=2.05]\n",
      "train epoch 11: 100%|██████████| 43/43 [00:00<00:00, 340.23batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 406.53batch/s, acc=0.511, loss=2.07]\n",
      "train epoch 12: 100%|██████████| 43/43 [00:00<00:00, 338.38batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.53batch/s, acc=0.533, loss=2.06]\n",
      "train epoch 13: 100%|██████████| 43/43 [00:00<00:00, 340.35batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.56batch/s, acc=0.535, loss=2.06]\n",
      "train epoch 14: 100%|██████████| 43/43 [00:00<00:00, 336.04batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.39batch/s, acc=0.538, loss=2.05]\n",
      "train epoch 15: 100%|██████████| 43/43 [00:00<00:00, 330.77batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.57batch/s, acc=0.541, loss=2.06]\n",
      "train epoch 16: 100%|██████████| 43/43 [00:00<00:00, 335.68batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.07batch/s, acc=0.546, loss=2.03]\n",
      "train epoch 17: 100%|██████████| 43/43 [00:00<00:00, 178.06batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.33batch/s, acc=0.55, loss=2.06]\n",
      "train epoch 18: 100%|██████████| 43/43 [00:00<00:00, 337.41batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 413.60batch/s, acc=0.551, loss=2.07]\n",
      "train epoch 19: 100%|██████████| 43/43 [00:00<00:00, 328.63batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 337.98batch/s, acc=0.551, loss=2.05]\n",
      "train epoch 20: 100%|██████████| 43/43 [00:00<00:00, 315.88batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 409.56batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 21: 100%|██████████| 43/43 [00:00<00:00, 334.77batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 340.18batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 22: 100%|██████████| 43/43 [00:00<00:00, 322.88batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 404.80batch/s, acc=0.554, loss=2.02]\n",
      "train epoch 23: 100%|██████████| 43/43 [00:00<00:00, 328.44batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 386.98batch/s, acc=0.557, loss=2.07]\n",
      "train epoch 24: 100%|██████████| 43/43 [00:00<00:00, 333.12batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.78batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 25: 100%|██████████| 43/43 [00:00<00:00, 329.32batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.83batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 26: 100%|██████████| 43/43 [00:00<00:00, 335.28batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 381.90batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 27: 100%|██████████| 43/43 [00:00<00:00, 337.64batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.22batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 28: 100%|██████████| 43/43 [00:00<00:00, 327.53batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 406.13batch/s, acc=0.551, loss=2.05]\n",
      "train epoch 29: 100%|██████████| 43/43 [00:00<00:00, 333.50batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.79batch/s, acc=0.546, loss=2.04]\n",
      "train epoch 30: 100%|██████████| 43/43 [00:00<00:00, 345.65batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.87batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 31: 100%|██████████| 43/43 [00:00<00:00, 326.47batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 460.15batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 32: 100%|██████████| 43/43 [00:00<00:00, 327.79batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.46batch/s, acc=0.551, loss=2.05]\n",
      "train epoch 33: 100%|██████████| 43/43 [00:00<00:00, 329.62batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 448.90batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 34: 100%|██████████| 43/43 [00:00<00:00, 324.44batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 373.94batch/s, acc=0.552, loss=2.03]\n",
      "train epoch 35: 100%|██████████| 43/43 [00:00<00:00, 330.23batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 406.12batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 36: 100%|██████████| 43/43 [00:00<00:00, 330.34batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 369.07batch/s, acc=0.552, loss=2.05]\n",
      "train epoch 37: 100%|██████████| 43/43 [00:00<00:00, 324.74batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 432.31batch/s, acc=0.557, loss=2.02]\n",
      "train epoch 38: 100%|██████████| 43/43 [00:00<00:00, 175.12batch/s, loss=2.12]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.78batch/s, acc=0.554, loss=2.07]\n",
      "train epoch 39: 100%|██████████| 43/43 [00:00<00:00, 337.58batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 389.21batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 40: 100%|██████████| 43/43 [00:00<00:00, 325.09batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 354.36batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 41: 100%|██████████| 43/43 [00:00<00:00, 321.76batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 348.13batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 42: 100%|██████████| 43/43 [00:00<00:00, 319.43batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 415.50batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 43: 100%|██████████| 43/43 [00:00<00:00, 326.87batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 366.55batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 44: 100%|██████████| 43/43 [00:00<00:00, 327.94batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 424.10batch/s, acc=0.555, loss=2.05]\n",
      "train epoch 45: 100%|██████████| 43/43 [00:00<00:00, 329.34batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 440.69batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 46: 100%|██████████| 43/43 [00:00<00:00, 331.97batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.16batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 47: 100%|██████████| 43/43 [00:00<00:00, 328.48batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.16batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 48: 100%|██████████| 43/43 [00:00<00:00, 332.40batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 410.62batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 49: 100%|██████████| 43/43 [00:00<00:00, 331.46batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.88batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 50: 100%|██████████| 43/43 [00:00<00:00, 335.42batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 473.64batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 51: 100%|██████████| 43/43 [00:00<00:00, 331.19batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 364.59batch/s, acc=0.555, loss=2.07]\n",
      "train epoch 52: 100%|██████████| 43/43 [00:00<00:00, 330.10batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 369.12batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 53: 100%|██████████| 43/43 [00:00<00:00, 329.10batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.97batch/s, acc=0.557, loss=2.04]\n",
      "train epoch 54: 100%|██████████| 43/43 [00:00<00:00, 323.81batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.50batch/s, acc=0.553, loss=2.03]\n",
      "train epoch 55: 100%|██████████| 43/43 [00:00<00:00, 331.82batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 365.84batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 56: 100%|██████████| 43/43 [00:00<00:00, 340.59batch/s, loss=2.1] \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.96batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 57: 100%|██████████| 43/43 [00:00<00:00, 320.26batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.80batch/s, acc=0.552, loss=2.05]\n",
      "train epoch 58: 100%|██████████| 43/43 [00:00<00:00, 316.52batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.02batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 59: 100%|██████████| 43/43 [00:00<00:00, 179.22batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 420.14batch/s, acc=0.552, loss=2.05]\n",
      "train epoch 60: 100%|██████████| 43/43 [00:00<00:00, 340.20batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 382.22batch/s, acc=0.549, loss=2.03]\n",
      "train epoch 61: 100%|██████████| 43/43 [00:00<00:00, 328.95batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 478.21batch/s, acc=0.554, loss=2.09]\n",
      "train epoch 62: 100%|██████████| 43/43 [00:00<00:00, 330.81batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 427.45batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 63: 100%|██████████| 43/43 [00:00<00:00, 340.74batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 320.25batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 64: 100%|██████████| 43/43 [00:00<00:00, 329.28batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 409.05batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 65: 100%|██████████| 43/43 [00:00<00:00, 330.22batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.81batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 66: 100%|██████████| 43/43 [00:00<00:00, 339.80batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 390.28batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 67: 100%|██████████| 43/43 [00:00<00:00, 326.60batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 424.88batch/s, acc=0.557, loss=2.04]\n",
      "train epoch 68: 100%|██████████| 43/43 [00:00<00:00, 340.66batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 457.59batch/s, acc=0.553, loss=2.05]\n",
      "train epoch 69: 100%|██████████| 43/43 [00:00<00:00, 328.41batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 445.72batch/s, acc=0.564, loss=2.06]\n",
      "train epoch 70: 100%|██████████| 43/43 [00:00<00:00, 334.58batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 431.78batch/s, acc=0.56, loss=2.08]\n",
      "train epoch 71: 100%|██████████| 43/43 [00:00<00:00, 325.10batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 370.97batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 72: 100%|██████████| 43/43 [00:00<00:00, 330.23batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.11batch/s, acc=0.563, loss=2.04]\n",
      "train epoch 73: 100%|██████████| 43/43 [00:00<00:00, 335.31batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 415.44batch/s, acc=0.557, loss=2.09]\n",
      "train epoch 74: 100%|██████████| 43/43 [00:00<00:00, 327.59batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.03batch/s, acc=0.543, loss=2.05]\n",
      "train epoch 75: 100%|██████████| 43/43 [00:00<00:00, 321.88batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 396.42batch/s, acc=0.553, loss=2.05]\n",
      "train epoch 76: 100%|██████████| 43/43 [00:00<00:00, 314.90batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 383.46batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 77: 100%|██████████| 43/43 [00:00<00:00, 316.49batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 351.53batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 78: 100%|██████████| 43/43 [00:00<00:00, 317.14batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.96batch/s, acc=0.56, loss=2.04]\n",
      "train epoch 79: 100%|██████████| 43/43 [00:00<00:00, 341.93batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 404.42batch/s, acc=0.546, loss=2.04]\n",
      "train epoch 80: 100%|██████████| 43/43 [00:00<00:00, 177.70batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 380.68batch/s, acc=0.551, loss=2.06]\n",
      "train epoch 81: 100%|██████████| 43/43 [00:00<00:00, 339.98batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.96batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 82: 100%|██████████| 43/43 [00:00<00:00, 345.18batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 379.22batch/s, acc=0.551, loss=2.07]\n",
      "train epoch 83: 100%|██████████| 43/43 [00:00<00:00, 328.71batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 413.52batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 84: 100%|██████████| 43/43 [00:00<00:00, 310.68batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.07batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 85: 100%|██████████| 43/43 [00:00<00:00, 320.59batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.88batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 86: 100%|██████████| 43/43 [00:00<00:00, 313.95batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 388.02batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 87: 100%|██████████| 43/43 [00:00<00:00, 325.92batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 404.04batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 88: 100%|██████████| 43/43 [00:00<00:00, 317.01batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 499.81batch/s, acc=0.557, loss=2.04]\n",
      "train epoch 89: 100%|██████████| 43/43 [00:00<00:00, 329.54batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 443.29batch/s, acc=0.553, loss=2.03]\n",
      "train epoch 90: 100%|██████████| 43/43 [00:00<00:00, 303.58batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 444.59batch/s, acc=0.56, loss=2.07]\n",
      "train epoch 91: 100%|██████████| 43/43 [00:00<00:00, 358.21batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 477.25batch/s, acc=0.553, loss=2.07]\n",
      "train epoch 92: 100%|██████████| 43/43 [00:00<00:00, 356.45batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.00batch/s, acc=0.559, loss=2.01]\n",
      "train epoch 93: 100%|██████████| 43/43 [00:00<00:00, 368.42batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 433.83batch/s, acc=0.553, loss=2.03]\n",
      "train epoch 94: 100%|██████████| 43/43 [00:00<00:00, 360.92batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 446.00batch/s, acc=0.552, loss=2.01]\n",
      "train epoch 95: 100%|██████████| 43/43 [00:00<00:00, 357.86batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 448.38batch/s, acc=0.561, loss=2.08]\n",
      "train epoch 96: 100%|██████████| 43/43 [00:00<00:00, 368.87batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 452.74batch/s, acc=0.559, loss=2.03]\n",
      "train epoch 97: 100%|██████████| 43/43 [00:00<00:00, 376.11batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.90batch/s, acc=0.552, loss=2.03]\n",
      "train epoch 98: 100%|██████████| 43/43 [00:00<00:00, 374.20batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 459.00batch/s, acc=0.561, loss=2.03]\n",
      "train epoch 99: 100%|██████████| 43/43 [00:00<00:00, 380.98batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 461.01batch/s, acc=0.56, loss=2.03]\n",
      "train epoch 100: 100%|██████████| 43/43 [00:00<00:00, 370.05batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 470.72batch/s, acc=0.548, loss=2.06]\n",
      "train epoch 101: 100%|██████████| 43/43 [00:00<00:00, 191.95batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 471.95batch/s, acc=0.552, loss=2.06]\n",
      "train epoch 102: 100%|██████████| 43/43 [00:00<00:00, 403.01batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 500.27batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 103: 100%|██████████| 43/43 [00:00<00:00, 394.57batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 459.47batch/s, acc=0.562, loss=2.04]\n",
      "train epoch 104: 100%|██████████| 43/43 [00:00<00:00, 397.12batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 491.32batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 105: 100%|██████████| 43/43 [00:00<00:00, 407.85batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 475.77batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 106: 100%|██████████| 43/43 [00:00<00:00, 381.78batch/s, loss=1.97]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 506.39batch/s, acc=0.555, loss=2.03]\n",
      "train epoch 107: 100%|██████████| 43/43 [00:00<00:00, 382.78batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 494.53batch/s, acc=0.553, loss=2.08]\n",
      "train epoch 108: 100%|██████████| 43/43 [00:00<00:00, 392.09batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 470.50batch/s, acc=0.553, loss=2.03]\n",
      "train epoch 109: 100%|██████████| 43/43 [00:00<00:00, 393.18batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 481.85batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 110: 100%|██████████| 43/43 [00:00<00:00, 379.43batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 498.54batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 111: 100%|██████████| 43/43 [00:00<00:00, 389.79batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 492.65batch/s, acc=0.554, loss=2.08]\n",
      "train epoch 112: 100%|██████████| 43/43 [00:00<00:00, 386.81batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 540.41batch/s, acc=0.563, loss=2.06]\n",
      "train epoch 113: 100%|██████████| 43/43 [00:00<00:00, 385.70batch/s, loss=1.97]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 504.13batch/s, acc=0.565, loss=2.06]\n",
      "train epoch 114: 100%|██████████| 43/43 [00:00<00:00, 387.52batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 490.34batch/s, acc=0.566, loss=2.03]\n",
      "train epoch 115: 100%|██████████| 43/43 [00:00<00:00, 365.19batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 488.78batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 116: 100%|██████████| 43/43 [00:00<00:00, 380.89batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 473.32batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 117: 100%|██████████| 43/43 [00:00<00:00, 355.84batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 290.01batch/s, acc=0.556, loss=2.08]\n",
      "train epoch 118: 100%|██████████| 43/43 [00:00<00:00, 349.95batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 501.19batch/s, acc=0.557, loss=2.02]\n",
      "train epoch 119: 100%|██████████| 43/43 [00:00<00:00, 399.47batch/s, loss=2.12]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 501.25batch/s, acc=0.553, loss=2.05]\n",
      "train epoch 120: 100%|██████████| 43/43 [00:00<00:00, 391.45batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 537.52batch/s, acc=0.553, loss=2.06]\n",
      "train epoch 121: 100%|██████████| 43/43 [00:00<00:00, 398.10batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 534.63batch/s, acc=0.56, loss=2.04]\n",
      "train epoch 122: 100%|██████████| 43/43 [00:00<00:00, 195.46batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 511.79batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 123: 100%|██████████| 43/43 [00:00<00:00, 405.13batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 526.44batch/s, acc=0.549, loss=2.06]\n",
      "train epoch 124: 100%|██████████| 43/43 [00:00<00:00, 402.45batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 488.51batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 125: 100%|██████████| 43/43 [00:00<00:00, 395.87batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 515.65batch/s, acc=0.552, loss=2.07]\n",
      "train epoch 126: 100%|██████████| 43/43 [00:00<00:00, 400.43batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 500.43batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 127: 100%|██████████| 43/43 [00:00<00:00, 396.29batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 529.18batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 128: 100%|██████████| 43/43 [00:00<00:00, 394.71batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 499.90batch/s, acc=0.554, loss=2.07]\n",
      "train epoch 129: 100%|██████████| 43/43 [00:00<00:00, 387.66batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 511.11batch/s, acc=0.555, loss=2.07]\n",
      "train epoch 130: 100%|██████████| 43/43 [00:00<00:00, 398.89batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 500.77batch/s, acc=0.552, loss=2.06]\n",
      "train epoch 131: 100%|██████████| 43/43 [00:00<00:00, 395.98batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 489.39batch/s, acc=0.553, loss=2.09]\n",
      "train epoch 132: 100%|██████████| 43/43 [00:00<00:00, 389.48batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 476.32batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 133: 100%|██████████| 43/43 [00:00<00:00, 388.23batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 495.72batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 134: 100%|██████████| 43/43 [00:00<00:00, 376.30batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 479.50batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 135: 100%|██████████| 43/43 [00:00<00:00, 377.73batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 501.79batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 136: 100%|██████████| 43/43 [00:00<00:00, 390.33batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 478.62batch/s, acc=0.555, loss=2.05]\n",
      "train epoch 137: 100%|██████████| 43/43 [00:00<00:00, 398.83batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 493.81batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 138: 100%|██████████| 43/43 [00:00<00:00, 382.58batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 500.52batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 139: 100%|██████████| 43/43 [00:00<00:00, 392.75batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 485.99batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 140: 100%|██████████| 43/43 [00:00<00:00, 393.39batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 472.19batch/s, acc=0.556, loss=2.03]\n",
      "train epoch 141: 100%|██████████| 43/43 [00:00<00:00, 391.82batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 495.24batch/s, acc=0.553, loss=2.05]\n",
      "train epoch 142: 100%|██████████| 43/43 [00:00<00:00, 432.81batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 574.60batch/s, acc=0.564, loss=2.05]\n",
      "train epoch 143: 100%|██████████| 43/43 [00:00<00:00, 204.56batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 548.21batch/s, acc=0.557, loss=2.04]\n",
      "train epoch 144: 100%|██████████| 43/43 [00:00<00:00, 436.64batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 552.84batch/s, acc=0.554, loss=2.07]\n",
      "train epoch 145: 100%|██████████| 43/43 [00:00<00:00, 440.48batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 543.53batch/s, acc=0.552, loss=2.08]\n",
      "train epoch 146: 100%|██████████| 43/43 [00:00<00:00, 398.49batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 546.33batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 147: 100%|██████████| 43/43 [00:00<00:00, 400.22batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 500.33batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 148: 100%|██████████| 43/43 [00:00<00:00, 400.01batch/s, loss=2.1] \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 550.35batch/s, acc=0.555, loss=2.03]\n",
      "train epoch 149: 100%|██████████| 43/43 [00:00<00:00, 387.32batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 516.35batch/s, acc=0.557, loss=2.04]\n",
      "train epoch 150: 100%|██████████| 43/43 [00:00<00:00, 402.04batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 477.72batch/s, acc=0.562, loss=2.04]\n",
      "train epoch 151: 100%|██████████| 43/43 [00:00<00:00, 401.30batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 508.04batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 152: 100%|██████████| 43/43 [00:00<00:00, 396.34batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 505.91batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 153: 100%|██████████| 43/43 [00:00<00:00, 399.09batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 513.58batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 154: 100%|██████████| 43/43 [00:00<00:00, 393.18batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 495.91batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 155: 100%|██████████| 43/43 [00:00<00:00, 392.72batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 476.40batch/s, acc=0.551, loss=2.09]\n",
      "train epoch 156: 100%|██████████| 43/43 [00:00<00:00, 378.76batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 505.00batch/s, acc=0.555, loss=2.05]\n",
      "train epoch 157: 100%|██████████| 43/43 [00:00<00:00, 401.86batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 514.41batch/s, acc=0.549, loss=2.05]\n",
      "train epoch 158: 100%|██████████| 43/43 [00:00<00:00, 400.90batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 505.68batch/s, acc=0.552, loss=2.03]\n",
      "train epoch 159: 100%|██████████| 43/43 [00:00<00:00, 400.12batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 508.18batch/s, acc=0.55, loss=2.05]\n",
      "train epoch 160: 100%|██████████| 43/43 [00:00<00:00, 393.43batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 498.28batch/s, acc=0.551, loss=2.07]\n",
      "train epoch 161: 100%|██████████| 43/43 [00:00<00:00, 406.22batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 501.37batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 162: 100%|██████████| 43/43 [00:00<00:00, 398.10batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 498.93batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 163: 100%|██████████| 43/43 [00:00<00:00, 404.95batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 512.39batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 164: 100%|██████████| 43/43 [00:00<00:00, 196.78batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 479.24batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 165: 100%|██████████| 43/43 [00:00<00:00, 398.90batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 495.59batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 166: 100%|██████████| 43/43 [00:00<00:00, 400.36batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 518.91batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 167: 100%|██████████| 43/43 [00:00<00:00, 396.15batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 475.64batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 168: 100%|██████████| 43/43 [00:00<00:00, 392.98batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 507.84batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 169: 100%|██████████| 43/43 [00:00<00:00, 399.09batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 474.69batch/s, acc=0.552, loss=2.05]\n",
      "train epoch 170: 100%|██████████| 43/43 [00:00<00:00, 398.96batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 498.56batch/s, acc=0.553, loss=2.06]\n",
      "train epoch 171: 100%|██████████| 43/43 [00:00<00:00, 403.98batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 486.92batch/s, acc=0.563, loss=2.06]\n",
      "train epoch 172: 100%|██████████| 43/43 [00:00<00:00, 404.62batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 505.22batch/s, acc=0.557, loss=2.08]\n",
      "train epoch 173: 100%|██████████| 43/43 [00:00<00:00, 400.58batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 455.37batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 174: 100%|██████████| 43/43 [00:00<00:00, 400.68batch/s, loss=1.97]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 507.11batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 175: 100%|██████████| 43/43 [00:00<00:00, 394.65batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 505.27batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 176: 100%|██████████| 43/43 [00:00<00:00, 385.78batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 508.68batch/s, acc=0.555, loss=2.05]\n",
      "train epoch 177: 100%|██████████| 43/43 [00:00<00:00, 381.26batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 481.83batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 178: 100%|██████████| 43/43 [00:00<00:00, 383.07batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 571.43batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 179: 100%|██████████| 43/43 [00:00<00:00, 434.56batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 571.91batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 180: 100%|██████████| 43/43 [00:00<00:00, 431.59batch/s, loss=2]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 564.31batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 181: 100%|██████████| 43/43 [00:00<00:00, 430.85batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 554.09batch/s, acc=0.555, loss=2.08]\n",
      "train epoch 182: 100%|██████████| 43/43 [00:00<00:00, 436.43batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 556.97batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 183: 100%|██████████| 43/43 [00:00<00:00, 415.90batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 554.17batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 184: 100%|██████████| 43/43 [00:00<00:00, 432.68batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 578.90batch/s, acc=0.557, loss=2.03]\n",
      "train epoch 185: 100%|██████████| 43/43 [00:00<00:00, 201.49batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 547.89batch/s, acc=0.563, loss=2.06]\n",
      "train epoch 186: 100%|██████████| 43/43 [00:00<00:00, 426.12batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 529.61batch/s, acc=0.551, loss=2.03]\n",
      "train epoch 187: 100%|██████████| 43/43 [00:00<00:00, 437.27batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 554.29batch/s, acc=0.564, loss=2.06]\n",
      "train epoch 188: 100%|██████████| 43/43 [00:00<00:00, 434.36batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 564.34batch/s, acc=0.565, loss=2.04]\n",
      "train epoch 189: 100%|██████████| 43/43 [00:00<00:00, 432.37batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 542.22batch/s, acc=0.556, loss=2.03]\n",
      "train epoch 190: 100%|██████████| 43/43 [00:00<00:00, 434.10batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 549.46batch/s, acc=0.563, loss=2.05]\n",
      "train epoch 191: 100%|██████████| 43/43 [00:00<00:00, 415.89batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 518.78batch/s, acc=0.562, loss=2.06]\n",
      "train epoch 192: 100%|██████████| 43/43 [00:00<00:00, 420.04batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 557.32batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 193: 100%|██████████| 43/43 [00:00<00:00, 434.51batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 544.66batch/s, acc=0.555, loss=2.05]\n",
      "train epoch 194: 100%|██████████| 43/43 [00:00<00:00, 439.05batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 557.37batch/s, acc=0.555, loss=2.09]\n",
      "train epoch 195: 100%|██████████| 43/43 [00:00<00:00, 431.62batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 543.63batch/s, acc=0.56, loss=2.02]\n",
      "train epoch 196: 100%|██████████| 43/43 [00:00<00:00, 402.90batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 510.98batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 197: 100%|██████████| 43/43 [00:00<00:00, 432.83batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 559.21batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 198: 100%|██████████| 43/43 [00:00<00:00, 430.61batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 559.81batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 199: 100%|██████████| 43/43 [00:00<00:00, 421.45batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 543.43batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 200: 100%|██████████| 43/43 [00:00<00:00, 431.88batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 574.82batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 201: 100%|██████████| 43/43 [00:00<00:00, 431.20batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 559.07batch/s, acc=0.555, loss=2.04]\n",
      "train epoch 202: 100%|██████████| 43/43 [00:00<00:00, 435.89batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 499.84batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 203: 100%|██████████| 43/43 [00:00<00:00, 414.73batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 518.48batch/s, acc=0.554, loss=2.03]\n",
      "train epoch 204: 100%|██████████| 43/43 [00:00<00:00, 413.18batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 533.86batch/s, acc=0.559, loss=2.07]\n",
      "train epoch 205: 100%|██████████| 43/43 [00:00<00:00, 418.48batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 521.07batch/s, acc=0.563, loss=2.05]\n",
      "train epoch 206: 100%|██████████| 43/43 [00:00<00:00, 198.43batch/s, loss=2.1] \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 524.77batch/s, acc=0.549, loss=2.04]\n",
      "train epoch 207: 100%|██████████| 43/43 [00:00<00:00, 413.03batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 537.39batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 208: 100%|██████████| 43/43 [00:00<00:00, 416.55batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 535.59batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 209: 100%|██████████| 43/43 [00:00<00:00, 411.54batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 532.97batch/s, acc=0.56, loss=2.03]\n",
      "train epoch 210: 100%|██████████| 43/43 [00:00<00:00, 414.97batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 537.21batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 211: 100%|██████████| 43/43 [00:00<00:00, 431.89batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 552.52batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 212: 100%|██████████| 43/43 [00:00<00:00, 433.07batch/s, loss=2.12]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 546.15batch/s, acc=0.559, loss=2.03]\n",
      "train epoch 213: 100%|██████████| 43/43 [00:00<00:00, 424.29batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 550.57batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 214: 100%|██████████| 43/43 [00:00<00:00, 419.38batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 544.25batch/s, acc=0.563, loss=2.06]\n",
      "train epoch 215: 100%|██████████| 43/43 [00:00<00:00, 435.10batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 562.36batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 216: 100%|██████████| 43/43 [00:00<00:00, 433.76batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 501.63batch/s, acc=0.565, loss=2.05]\n",
      "train epoch 217: 100%|██████████| 43/43 [00:00<00:00, 427.18batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 551.31batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 218: 100%|██████████| 43/43 [00:00<00:00, 423.08batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 533.85batch/s, acc=0.556, loss=2.08]\n",
      "train epoch 219: 100%|██████████| 43/43 [00:00<00:00, 436.76batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 567.24batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 220: 100%|██████████| 43/43 [00:00<00:00, 432.32batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 544.04batch/s, acc=0.556, loss=2.08]\n",
      "train epoch 221: 100%|██████████| 43/43 [00:00<00:00, 436.22batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 563.15batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 222: 100%|██████████| 43/43 [00:00<00:00, 421.69batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 520.67batch/s, acc=0.56, loss=2]\n",
      "train epoch 223: 100%|██████████| 43/43 [00:00<00:00, 427.53batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 556.64batch/s, acc=0.551, loss=2.06]\n",
      "train epoch 224: 100%|██████████| 43/43 [00:00<00:00, 431.54batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 536.66batch/s, acc=0.55, loss=2.06]\n",
      "train epoch 225: 100%|██████████| 43/43 [00:00<00:00, 439.92batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 512.66batch/s, acc=0.555, loss=2.02]\n",
      "train epoch 226: 100%|██████████| 43/43 [00:00<00:00, 389.40batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 450.33batch/s, acc=0.563, loss=2.06]\n",
      "train epoch 227: 100%|██████████| 43/43 [00:00<00:00, 194.90batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 482.33batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 228: 100%|██████████| 43/43 [00:00<00:00, 400.75batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 516.88batch/s, acc=0.56, loss=2.06]\n",
      "train epoch 229: 100%|██████████| 43/43 [00:00<00:00, 394.00batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 521.76batch/s, acc=0.554, loss=2.07]\n",
      "train epoch 230: 100%|██████████| 43/43 [00:00<00:00, 397.94batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 510.48batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 231: 100%|██████████| 43/43 [00:00<00:00, 387.69batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 490.51batch/s, acc=0.551, loss=2.03]\n",
      "train epoch 232: 100%|██████████| 43/43 [00:00<00:00, 393.54batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 486.57batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 233: 100%|██████████| 43/43 [00:00<00:00, 404.36batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 504.04batch/s, acc=0.555, loss=2.07]\n",
      "train epoch 234: 100%|██████████| 43/43 [00:00<00:00, 401.04batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 501.37batch/s, acc=0.559, loss=2.04]\n",
      "train epoch 235: 100%|██████████| 43/43 [00:00<00:00, 403.28batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 506.75batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 236: 100%|██████████| 43/43 [00:00<00:00, 399.30batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 522.03batch/s, acc=0.552, loss=2.06]\n",
      "train epoch 237: 100%|██████████| 43/43 [00:00<00:00, 395.78batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 505.58batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 238: 100%|██████████| 43/43 [00:00<00:00, 397.06batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 545.20batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 239: 100%|██████████| 43/43 [00:00<00:00, 374.31batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 483.26batch/s, acc=0.558, loss=2.02]\n",
      "train epoch 240: 100%|██████████| 43/43 [00:00<00:00, 387.54batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 520.71batch/s, acc=0.551, loss=2.06]\n",
      "train epoch 241: 100%|██████████| 43/43 [00:00<00:00, 390.33batch/s, loss=2.09]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 475.67batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 242: 100%|██████████| 43/43 [00:00<00:00, 396.38batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 490.52batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 243: 100%|██████████| 43/43 [00:00<00:00, 381.94batch/s, loss=2.1] \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 508.73batch/s, acc=0.554, loss=2.03]\n",
      "train epoch 244: 100%|██████████| 43/43 [00:00<00:00, 386.74batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 481.24batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 245: 100%|██████████| 43/43 [00:00<00:00, 383.86batch/s, loss=2.1] \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 485.05batch/s, acc=0.556, loss=2.06]\n",
      "train epoch 246: 100%|██████████| 43/43 [00:00<00:00, 388.26batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 497.58batch/s, acc=0.556, loss=2.07]\n",
      "train epoch 247: 100%|██████████| 43/43 [00:00<00:00, 391.85batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 484.82batch/s, acc=0.564, loss=2.04]\n",
      "train epoch 248: 100%|██████████| 43/43 [00:00<00:00, 391.40batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 87.91batch/s, acc=0.551, loss=2.04]\n",
      "train epoch 249: 100%|██████████| 43/43 [00:00<00:00, 394.36batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 506.65batch/s, acc=0.55, loss=2.04]\n",
      "train epoch 250: 100%|██████████| 43/43 [00:00<00:00, 413.08batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 532.30batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 251: 100%|██████████| 43/43 [00:00<00:00, 412.82batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 535.03batch/s, acc=0.557, loss=2.03]\n",
      "train epoch 252: 100%|██████████| 43/43 [00:00<00:00, 411.11batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 550.73batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 253: 100%|██████████| 43/43 [00:00<00:00, 412.35batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 514.94batch/s, acc=0.556, loss=2.03]\n",
      "train epoch 254: 100%|██████████| 43/43 [00:00<00:00, 409.58batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 474.20batch/s, acc=0.555, loss=2.03]\n",
      "train epoch 255: 100%|██████████| 43/43 [00:00<00:00, 404.51batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 582.99batch/s, acc=0.553, loss=2.03]\n",
      "train epoch 256: 100%|██████████| 43/43 [00:00<00:00, 407.66batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 535.76batch/s, acc=0.552, loss=2.07]\n",
      "train epoch 257: 100%|██████████| 43/43 [00:00<00:00, 413.99batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 517.76batch/s, acc=0.556, loss=2.04]\n",
      "train epoch 258: 100%|██████████| 43/43 [00:00<00:00, 402.31batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 529.52batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 259: 100%|██████████| 43/43 [00:00<00:00, 403.60batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 535.57batch/s, acc=0.555, loss=2.05]\n",
      "train epoch 260: 100%|██████████| 43/43 [00:00<00:00, 396.20batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 572.17batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 261: 100%|██████████| 43/43 [00:00<00:00, 406.01batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 533.63batch/s, acc=0.561, loss=2.05]\n",
      "train epoch 262: 100%|██████████| 43/43 [00:00<00:00, 409.66batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 522.08batch/s, acc=0.55, loss=2.07]\n",
      "train epoch 263: 100%|██████████| 43/43 [00:00<00:00, 407.79batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 510.32batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 264: 100%|██████████| 43/43 [00:00<00:00, 411.03batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 578.29batch/s, acc=0.561, loss=2.05]\n",
      "train epoch 265: 100%|██████████| 43/43 [00:00<00:00, 414.32batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 509.84batch/s, acc=0.549, loss=2.06]\n",
      "train epoch 266: 100%|██████████| 43/43 [00:00<00:00, 409.57batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 507.81batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 267: 100%|██████████| 43/43 [00:00<00:00, 412.24batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 520.37batch/s, acc=0.558, loss=2.06]\n",
      "train epoch 268: 100%|██████████| 43/43 [00:00<00:00, 411.11batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 515.33batch/s, acc=0.561, loss=2.06]\n",
      "train epoch 269: 100%|██████████| 43/43 [00:00<00:00, 405.62batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 86.92batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 270: 100%|██████████| 43/43 [00:00<00:00, 414.60batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 506.31batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 271: 100%|██████████| 43/43 [00:00<00:00, 413.49batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 487.52batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 272: 100%|██████████| 43/43 [00:00<00:00, 417.92batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 536.49batch/s, acc=0.554, loss=2.05]\n",
      "train epoch 273: 100%|██████████| 43/43 [00:00<00:00, 411.89batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 501.78batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 274: 100%|██████████| 43/43 [00:00<00:00, 415.18batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 540.23batch/s, acc=0.554, loss=2.03]\n",
      "train epoch 275: 100%|██████████| 43/43 [00:00<00:00, 410.65batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 535.23batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 276: 100%|██████████| 43/43 [00:00<00:00, 410.31batch/s, loss=1.96]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 519.18batch/s, acc=0.561, loss=2.04]\n",
      "train epoch 277: 100%|██████████| 43/43 [00:00<00:00, 406.86batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 530.62batch/s, acc=0.549, loss=2.06]\n",
      "train epoch 278: 100%|██████████| 43/43 [00:00<00:00, 410.75batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 551.91batch/s, acc=0.555, loss=2.05]\n",
      "train epoch 279: 100%|██████████| 43/43 [00:00<00:00, 408.78batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 528.71batch/s, acc=0.559, loss=2.05]\n",
      "train epoch 280: 100%|██████████| 43/43 [00:00<00:00, 408.63batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 525.02batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 281: 100%|██████████| 43/43 [00:00<00:00, 406.94batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 520.32batch/s, acc=0.56, loss=2.05]\n",
      "train epoch 282: 100%|██████████| 43/43 [00:00<00:00, 409.99batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 586.09batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 283: 100%|██████████| 43/43 [00:00<00:00, 420.27batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 530.90batch/s, acc=0.549, loss=2.06]\n",
      "train epoch 284: 100%|██████████| 43/43 [00:00<00:00, 418.74batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 547.43batch/s, acc=0.562, loss=2.05]\n",
      "train epoch 285: 100%|██████████| 43/43 [00:00<00:00, 407.98batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 542.98batch/s, acc=0.552, loss=2.06]\n",
      "train epoch 286: 100%|██████████| 43/43 [00:00<00:00, 413.22batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 516.76batch/s, acc=0.558, loss=2.07]\n",
      "train epoch 287: 100%|██████████| 43/43 [00:00<00:00, 407.87batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 529.97batch/s, acc=0.553, loss=2.04]\n",
      "train epoch 288: 100%|██████████| 43/43 [00:00<00:00, 415.89batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.83batch/s, acc=0.554, loss=2.06]\n",
      "train epoch 289: 100%|██████████| 43/43 [00:00<00:00, 307.90batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 305.68batch/s, acc=0.555, loss=2.06]\n",
      "train epoch 290: 100%|██████████| 43/43 [00:00<00:00, 292.05batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 80.68batch/s, acc=0.561, loss=2.03]\n",
      "train epoch 291: 100%|██████████| 43/43 [00:00<00:00, 347.85batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.93batch/s, acc=0.554, loss=2.04]\n",
      "train epoch 292: 100%|██████████| 43/43 [00:00<00:00, 359.57batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 299.88batch/s, acc=0.556, loss=2.05]\n",
      "train epoch 293: 100%|██████████| 43/43 [00:00<00:00, 281.09batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 310.62batch/s, acc=0.563, loss=2.03]\n",
      "train epoch 294: 100%|██████████| 43/43 [00:00<00:00, 304.75batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 333.56batch/s, acc=0.557, loss=2.05]\n",
      "train epoch 295: 100%|██████████| 43/43 [00:00<00:00, 293.22batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 436.17batch/s, acc=0.558, loss=2.05]\n",
      "train epoch 296: 100%|██████████| 43/43 [00:00<00:00, 323.16batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.30batch/s, acc=0.559, loss=2.06]\n",
      "train epoch 297: 100%|██████████| 43/43 [00:00<00:00, 313.82batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 362.13batch/s, acc=0.553, loss=2.06]\n",
      "train epoch 298: 100%|██████████| 43/43 [00:00<00:00, 326.75batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 423.30batch/s, acc=0.558, loss=2.04]\n",
      "train epoch 299: 100%|██████████| 43/43 [00:00<00:00, 321.59batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.43batch/s, acc=0.557, loss=2.06]\n",
      "train epoch 300: 100%|██████████| 43/43 [00:00<00:00, 311.99batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.62batch/s, acc=0.552, loss=2.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 47/47 [00:00<00:00, 360.95batch/s, acc=0.635, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.46batch/s, acc=0.552, loss=2.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "retain:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 43/43 [00:00<00:00, 432.14batch/s, acc=0.642, loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "forget:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 5/5 [00:00<00:00, 417.96batch/s, acc=0.572, loss=2.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "surrogate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 59/59 [00:00<00:00, 449.80batch/s, acc=0.593, loss=2.05]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:50:20.329820Z",
     "start_time": "2024-12-30T01:49:14.900215Z"
    }
   },
   "source": [
    "# retrain from scratch\n",
    "surrmodel = nn.Linear(dim, num_classes, bias=False).to(device)\n",
    "optimizer = torch.optim.Adam(surrmodel.parameters(), lr=0.001)\n",
    "train(surr_loader, val_loader, surrmodel, criterion, optimizer, num_epoch=300, device=device)\n",
    "\n",
    "print_eval(surrmodel)\n",
    "surrmodel = surrmodel.to('cpu')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train epoch 1: 100%|██████████| 59/59 [00:00<00:00, 373.33batch/s, loss=2.37]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 475.99batch/s, acc=0.151, loss=2.35]\n",
      "train epoch 2: 100%|██████████| 59/59 [00:00<00:00, 390.13batch/s, loss=2.19]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 541.81batch/s, acc=0.245, loss=2.18]\n",
      "train epoch 3: 100%|██████████| 59/59 [00:00<00:00, 399.88batch/s, loss=2.11]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 522.36batch/s, acc=0.346, loss=2.16]\n",
      "train epoch 4: 100%|██████████| 59/59 [00:00<00:00, 395.59batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 610.47batch/s, acc=0.39, loss=2.11]\n",
      "train epoch 5: 100%|██████████| 59/59 [00:00<00:00, 387.38batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 582.99batch/s, acc=0.416, loss=2.1]\n",
      "train epoch 6: 100%|██████████| 59/59 [00:00<00:00, 398.72batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 558.79batch/s, acc=0.439, loss=2.07]\n",
      "train epoch 7: 100%|██████████| 59/59 [00:00<00:00, 227.35batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 521.23batch/s, acc=0.458, loss=2.12]\n",
      "train epoch 8: 100%|██████████| 59/59 [00:00<00:00, 369.50batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 478.94batch/s, acc=0.479, loss=2.07]\n",
      "train epoch 9: 100%|██████████| 59/59 [00:00<00:00, 343.88batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.76batch/s, acc=0.488, loss=2.08]\n",
      "train epoch 10: 100%|██████████| 59/59 [00:00<00:00, 337.61batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.86batch/s, acc=0.495, loss=2.09]\n",
      "train epoch 11: 100%|██████████| 59/59 [00:00<00:00, 331.12batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 403.05batch/s, acc=0.514, loss=2.09]\n",
      "train epoch 12: 100%|██████████| 59/59 [00:00<00:00, 318.50batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 366.29batch/s, acc=0.516, loss=2.04]\n",
      "train epoch 13: 100%|██████████| 59/59 [00:00<00:00, 328.55batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.32batch/s, acc=0.517, loss=2.08]\n",
      "train epoch 14: 100%|██████████| 59/59 [00:00<00:00, 314.39batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 290.59batch/s, acc=0.528, loss=2.08]\n",
      "train epoch 15: 100%|██████████| 59/59 [00:00<00:00, 283.33batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 290.47batch/s, acc=0.525, loss=2.04]\n",
      "train epoch 16: 100%|██████████| 59/59 [00:00<00:00, 315.30batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 331.19batch/s, acc=0.524, loss=2.1]\n",
      "train epoch 17: 100%|██████████| 59/59 [00:00<00:00, 322.06batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 349.28batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 18: 100%|██████████| 59/59 [00:00<00:00, 314.64batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 282.86batch/s, acc=0.528, loss=2.04]\n",
      "train epoch 19: 100%|██████████| 59/59 [00:00<00:00, 280.83batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 299.86batch/s, acc=0.529, loss=2.04]\n",
      "train epoch 20: 100%|██████████| 59/59 [00:00<00:00, 302.08batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 320.66batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 21: 100%|██████████| 59/59 [00:00<00:00, 318.56batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 290.64batch/s, acc=0.534, loss=2.06]\n",
      "train epoch 22: 100%|██████████| 59/59 [00:00<00:00, 299.31batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 311.15batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 23: 100%|██████████| 59/59 [00:00<00:00, 203.70batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 451.07batch/s, acc=0.531, loss=2.09]\n",
      "train epoch 24: 100%|██████████| 59/59 [00:00<00:00, 355.76batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 464.34batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 25: 100%|██████████| 59/59 [00:00<00:00, 308.48batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 475.77batch/s, acc=0.532, loss=2.07]\n",
      "train epoch 26: 100%|██████████| 59/59 [00:00<00:00, 354.03batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.69batch/s, acc=0.523, loss=2.06]\n",
      "train epoch 27: 100%|██████████| 59/59 [00:00<00:00, 357.45batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 484.34batch/s, acc=0.529, loss=2.03]\n",
      "train epoch 28: 100%|██████████| 59/59 [00:00<00:00, 362.97batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 389.62batch/s, acc=0.525, loss=2.05]\n",
      "train epoch 29: 100%|██████████| 59/59 [00:00<00:00, 363.90batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.18batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 30: 100%|██████████| 59/59 [00:00<00:00, 362.12batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 484.16batch/s, acc=0.528, loss=2.02]\n",
      "train epoch 31: 100%|██████████| 59/59 [00:00<00:00, 356.97batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 469.07batch/s, acc=0.529, loss=2.06]\n",
      "train epoch 32: 100%|██████████| 59/59 [00:00<00:00, 367.18batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 469.86batch/s, acc=0.532, loss=2.1]\n",
      "train epoch 33: 100%|██████████| 59/59 [00:00<00:00, 361.58batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 476.68batch/s, acc=0.525, loss=2.03]\n",
      "train epoch 34: 100%|██████████| 59/59 [00:00<00:00, 375.68batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 382.32batch/s, acc=0.53, loss=2.08]\n",
      "train epoch 35: 100%|██████████| 59/59 [00:00<00:00, 285.08batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 285.07batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 36: 100%|██████████| 59/59 [00:00<00:00, 281.36batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 339.57batch/s, acc=0.534, loss=2.04]\n",
      "train epoch 37: 100%|██████████| 59/59 [00:00<00:00, 335.45batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.28batch/s, acc=0.528, loss=2.09]\n",
      "train epoch 38: 100%|██████████| 59/59 [00:00<00:00, 296.11batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 350.45batch/s, acc=0.529, loss=2.05]\n",
      "train epoch 39: 100%|██████████| 59/59 [00:00<00:00, 200.02batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.39batch/s, acc=0.528, loss=2.03]\n",
      "train epoch 40: 100%|██████████| 59/59 [00:00<00:00, 331.42batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 338.60batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 41: 100%|██████████| 59/59 [00:00<00:00, 328.51batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 344.80batch/s, acc=0.522, loss=2.11]\n",
      "train epoch 42: 100%|██████████| 59/59 [00:00<00:00, 315.11batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 343.42batch/s, acc=0.529, loss=2.05]\n",
      "train epoch 43: 100%|██████████| 59/59 [00:00<00:00, 320.83batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 342.21batch/s, acc=0.53, loss=2.04]\n",
      "train epoch 44: 100%|██████████| 59/59 [00:00<00:00, 320.92batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 385.74batch/s, acc=0.528, loss=2.04]\n",
      "train epoch 45: 100%|██████████| 59/59 [00:00<00:00, 315.57batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 377.94batch/s, acc=0.53, loss=2.09]\n",
      "train epoch 46: 100%|██████████| 59/59 [00:00<00:00, 328.83batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 351.14batch/s, acc=0.527, loss=2.04]\n",
      "train epoch 47: 100%|██████████| 59/59 [00:00<00:00, 337.32batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.80batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 48: 100%|██████████| 59/59 [00:00<00:00, 320.61batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 316.65batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 49: 100%|██████████| 59/59 [00:00<00:00, 321.39batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 311.53batch/s, acc=0.529, loss=2.09]\n",
      "train epoch 50: 100%|██████████| 59/59 [00:00<00:00, 331.16batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 346.41batch/s, acc=0.534, loss=2.08]\n",
      "train epoch 51: 100%|██████████| 59/59 [00:00<00:00, 328.81batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 381.18batch/s, acc=0.524, loss=2.05]\n",
      "train epoch 52: 100%|██████████| 59/59 [00:00<00:00, 325.65batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 411.42batch/s, acc=0.536, loss=2.07]\n",
      "train epoch 53: 100%|██████████| 59/59 [00:00<00:00, 315.29batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.60batch/s, acc=0.531, loss=2.05]\n",
      "train epoch 54: 100%|██████████| 59/59 [00:00<00:00, 342.22batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 332.57batch/s, acc=0.521, loss=2.08]\n",
      "train epoch 55: 100%|██████████| 59/59 [00:00<00:00, 203.40batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 386.31batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 56: 100%|██████████| 59/59 [00:00<00:00, 328.82batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.87batch/s, acc=0.528, loss=2.08]\n",
      "train epoch 57: 100%|██████████| 59/59 [00:00<00:00, 312.94batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 349.29batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 58: 100%|██████████| 59/59 [00:00<00:00, 329.85batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 364.31batch/s, acc=0.531, loss=2.09]\n",
      "train epoch 59: 100%|██████████| 59/59 [00:00<00:00, 333.45batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 334.80batch/s, acc=0.527, loss=2.08]\n",
      "train epoch 60: 100%|██████████| 59/59 [00:00<00:00, 325.73batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 387.93batch/s, acc=0.53, loss=2.08]\n",
      "train epoch 61: 100%|██████████| 59/59 [00:00<00:00, 333.05batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 398.22batch/s, acc=0.529, loss=2.07]\n",
      "train epoch 62: 100%|██████████| 59/59 [00:00<00:00, 321.65batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.80batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 63: 100%|██████████| 59/59 [00:00<00:00, 337.70batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 345.64batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 64: 100%|██████████| 59/59 [00:00<00:00, 332.04batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 426.88batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 65: 100%|██████████| 59/59 [00:00<00:00, 324.92batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 366.50batch/s, acc=0.532, loss=2.09]\n",
      "train epoch 66: 100%|██████████| 59/59 [00:00<00:00, 327.58batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 336.45batch/s, acc=0.524, loss=2.07]\n",
      "train epoch 67: 100%|██████████| 59/59 [00:00<00:00, 325.20batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 362.60batch/s, acc=0.526, loss=2.07]\n",
      "train epoch 68: 100%|██████████| 59/59 [00:00<00:00, 321.54batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.56batch/s, acc=0.529, loss=2.05]\n",
      "train epoch 69: 100%|██████████| 59/59 [00:00<00:00, 331.24batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 416.94batch/s, acc=0.527, loss=2.09]\n",
      "train epoch 70: 100%|██████████| 59/59 [00:00<00:00, 328.16batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 361.59batch/s, acc=0.531, loss=2.05]\n",
      "train epoch 71: 100%|██████████| 59/59 [00:00<00:00, 325.76batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 83.00batch/s, acc=0.532, loss=2.08]\n",
      "train epoch 72: 100%|██████████| 59/59 [00:00<00:00, 329.94batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 330.55batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 73: 100%|██████████| 59/59 [00:00<00:00, 325.04batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.23batch/s, acc=0.53, loss=2.02]\n",
      "train epoch 74: 100%|██████████| 59/59 [00:00<00:00, 332.59batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 371.62batch/s, acc=0.523, loss=2.08]\n",
      "train epoch 75: 100%|██████████| 59/59 [00:00<00:00, 333.74batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 413.06batch/s, acc=0.533, loss=2.09]\n",
      "train epoch 76: 100%|██████████| 59/59 [00:00<00:00, 355.92batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 460.73batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 77: 100%|██████████| 59/59 [00:00<00:00, 339.67batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 409.12batch/s, acc=0.531, loss=2.08]\n",
      "train epoch 78: 100%|██████████| 59/59 [00:00<00:00, 356.29batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 390.80batch/s, acc=0.534, loss=2.09]\n",
      "train epoch 79: 100%|██████████| 59/59 [00:00<00:00, 344.03batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.95batch/s, acc=0.529, loss=2.07]\n",
      "train epoch 80: 100%|██████████| 59/59 [00:00<00:00, 340.76batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 352.00batch/s, acc=0.526, loss=2.08]\n",
      "train epoch 81: 100%|██████████| 59/59 [00:00<00:00, 333.54batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 344.45batch/s, acc=0.529, loss=2.03]\n",
      "train epoch 82: 100%|██████████| 59/59 [00:00<00:00, 344.38batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.49batch/s, acc=0.531, loss=2.06]\n",
      "train epoch 83: 100%|██████████| 59/59 [00:00<00:00, 337.23batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 374.81batch/s, acc=0.529, loss=2.04]\n",
      "train epoch 84: 100%|██████████| 59/59 [00:00<00:00, 334.95batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 441.09batch/s, acc=0.523, loss=2.05]\n",
      "train epoch 85: 100%|██████████| 59/59 [00:00<00:00, 342.56batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.20batch/s, acc=0.529, loss=2.06]\n",
      "train epoch 86: 100%|██████████| 59/59 [00:00<00:00, 323.65batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.51batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 87: 100%|██████████| 59/59 [00:00<00:00, 331.58batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 390.04batch/s, acc=0.524, loss=2.05]\n",
      "train epoch 88: 100%|██████████| 59/59 [00:00<00:00, 206.96batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 415.48batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 89: 100%|██████████| 59/59 [00:00<00:00, 336.17batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.21batch/s, acc=0.533, loss=2.08]\n",
      "train epoch 90: 100%|██████████| 59/59 [00:00<00:00, 326.72batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 410.93batch/s, acc=0.527, loss=2.09]\n",
      "train epoch 91: 100%|██████████| 59/59 [00:00<00:00, 342.39batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 309.37batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 92: 100%|██████████| 59/59 [00:00<00:00, 321.90batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 404.77batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 93: 100%|██████████| 59/59 [00:00<00:00, 324.00batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.79batch/s, acc=0.533, loss=2.04]\n",
      "train epoch 94: 100%|██████████| 59/59 [00:00<00:00, 328.96batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.00batch/s, acc=0.525, loss=2.04]\n",
      "train epoch 95: 100%|██████████| 59/59 [00:00<00:00, 327.12batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.48batch/s, acc=0.537, loss=2.07]\n",
      "train epoch 96: 100%|██████████| 59/59 [00:00<00:00, 330.32batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 380.19batch/s, acc=0.532, loss=2.07]\n",
      "train epoch 97: 100%|██████████| 59/59 [00:00<00:00, 334.41batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 372.06batch/s, acc=0.539, loss=2.07]\n",
      "train epoch 98: 100%|██████████| 59/59 [00:00<00:00, 328.06batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 381.35batch/s, acc=0.529, loss=2.05]\n",
      "train epoch 99: 100%|██████████| 59/59 [00:00<00:00, 325.23batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.97batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 100: 100%|██████████| 59/59 [00:00<00:00, 332.19batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 320.97batch/s, acc=0.529, loss=2.08]\n",
      "train epoch 101: 100%|██████████| 59/59 [00:00<00:00, 334.54batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.13batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 102: 100%|██████████| 59/59 [00:00<00:00, 320.76batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 434.32batch/s, acc=0.529, loss=2.07]\n",
      "train epoch 103: 100%|██████████| 59/59 [00:00<00:00, 340.18batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.98batch/s, acc=0.528, loss=2.08]\n",
      "train epoch 104: 100%|██████████| 59/59 [00:00<00:00, 202.48batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 364.68batch/s, acc=0.529, loss=2.11]\n",
      "train epoch 105: 100%|██████████| 59/59 [00:00<00:00, 336.01batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 357.35batch/s, acc=0.531, loss=2.08]\n",
      "train epoch 106: 100%|██████████| 59/59 [00:00<00:00, 335.97batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 406.01batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 107: 100%|██████████| 59/59 [00:00<00:00, 356.88batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 387.03batch/s, acc=0.524, loss=2.08]\n",
      "train epoch 108: 100%|██████████| 59/59 [00:00<00:00, 366.71batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 481.44batch/s, acc=0.529, loss=2.07]\n",
      "train epoch 109: 100%|██████████| 59/59 [00:00<00:00, 344.74batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 437.72batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 110: 100%|██████████| 59/59 [00:00<00:00, 328.45batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 420.50batch/s, acc=0.526, loss=2.05]\n",
      "train epoch 111: 100%|██████████| 59/59 [00:00<00:00, 342.15batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 401.69batch/s, acc=0.533, loss=2.05]\n",
      "train epoch 112: 100%|██████████| 59/59 [00:00<00:00, 342.58batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 409.83batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 113: 100%|██████████| 59/59 [00:00<00:00, 341.32batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.99batch/s, acc=0.528, loss=2.07]\n",
      "train epoch 114: 100%|██████████| 59/59 [00:00<00:00, 331.26batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 437.43batch/s, acc=0.527, loss=2.08]\n",
      "train epoch 115: 100%|██████████| 59/59 [00:00<00:00, 349.56batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 375.51batch/s, acc=0.532, loss=2.07]\n",
      "train epoch 116: 100%|██████████| 59/59 [00:00<00:00, 349.08batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 420.90batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 117: 100%|██████████| 59/59 [00:00<00:00, 339.91batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.32batch/s, acc=0.531, loss=2.08]\n",
      "train epoch 118: 100%|██████████| 59/59 [00:00<00:00, 326.01batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 336.12batch/s, acc=0.525, loss=2.05]\n",
      "train epoch 119: 100%|██████████| 59/59 [00:00<00:00, 334.32batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.84batch/s, acc=0.526, loss=2.06]\n",
      "train epoch 120: 100%|██████████| 59/59 [00:00<00:00, 212.28batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 429.95batch/s, acc=0.534, loss=2.08]\n",
      "train epoch 121: 100%|██████████| 59/59 [00:00<00:00, 366.99batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 442.51batch/s, acc=0.531, loss=2.05]\n",
      "train epoch 122: 100%|██████████| 59/59 [00:00<00:00, 353.09batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 424.31batch/s, acc=0.527, loss=2.04]\n",
      "train epoch 123: 100%|██████████| 59/59 [00:00<00:00, 350.97batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 435.18batch/s, acc=0.527, loss=2.05]\n",
      "train epoch 124: 100%|██████████| 59/59 [00:00<00:00, 356.04batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 401.78batch/s, acc=0.53, loss=2.1]\n",
      "train epoch 125: 100%|██████████| 59/59 [00:00<00:00, 345.81batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 436.02batch/s, acc=0.533, loss=2.04]\n",
      "train epoch 126: 100%|██████████| 59/59 [00:00<00:00, 340.08batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 423.60batch/s, acc=0.536, loss=2.08]\n",
      "train epoch 127: 100%|██████████| 59/59 [00:00<00:00, 344.78batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 413.32batch/s, acc=0.535, loss=2.08]\n",
      "train epoch 128: 100%|██████████| 59/59 [00:00<00:00, 353.67batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 407.09batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 129: 100%|██████████| 59/59 [00:00<00:00, 342.65batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 427.52batch/s, acc=0.529, loss=2.06]\n",
      "train epoch 130: 100%|██████████| 59/59 [00:00<00:00, 342.88batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 435.42batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 131: 100%|██████████| 59/59 [00:00<00:00, 342.40batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 442.08batch/s, acc=0.523, loss=2.08]\n",
      "train epoch 132: 100%|██████████| 59/59 [00:00<00:00, 351.66batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.12batch/s, acc=0.532, loss=2.04]\n",
      "train epoch 133: 100%|██████████| 59/59 [00:00<00:00, 330.98batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 401.78batch/s, acc=0.526, loss=2.09]\n",
      "train epoch 134: 100%|██████████| 59/59 [00:00<00:00, 350.54batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 350.82batch/s, acc=0.533, loss=2.06]\n",
      "train epoch 135: 100%|██████████| 59/59 [00:00<00:00, 355.94batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.08batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 136: 100%|██████████| 59/59 [00:00<00:00, 208.91batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 407.68batch/s, acc=0.528, loss=2.09]\n",
      "train epoch 137: 100%|██████████| 59/59 [00:00<00:00, 345.42batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 442.58batch/s, acc=0.531, loss=2.04]\n",
      "train epoch 138: 100%|██████████| 59/59 [00:00<00:00, 345.96batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 450.52batch/s, acc=0.529, loss=2.07]\n",
      "train epoch 139: 100%|██████████| 59/59 [00:00<00:00, 341.67batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 412.52batch/s, acc=0.529, loss=2.06]\n",
      "train epoch 140: 100%|██████████| 59/59 [00:00<00:00, 349.71batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 355.18batch/s, acc=0.525, loss=2.05]\n",
      "train epoch 141: 100%|██████████| 59/59 [00:00<00:00, 347.56batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 371.46batch/s, acc=0.529, loss=2.09]\n",
      "train epoch 142: 100%|██████████| 59/59 [00:00<00:00, 347.37batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.49batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 143: 100%|██████████| 59/59 [00:00<00:00, 348.95batch/s, loss=2.08]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 336.17batch/s, acc=0.528, loss=2.07]\n",
      "train epoch 144: 100%|██████████| 59/59 [00:00<00:00, 350.60batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.23batch/s, acc=0.533, loss=2.05]\n",
      "train epoch 145: 100%|██████████| 59/59 [00:00<00:00, 343.97batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 363.46batch/s, acc=0.537, loss=2.03]\n",
      "train epoch 146: 100%|██████████| 59/59 [00:00<00:00, 339.07batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.78batch/s, acc=0.532, loss=2.09]\n",
      "train epoch 147: 100%|██████████| 59/59 [00:00<00:00, 339.62batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 440.41batch/s, acc=0.524, loss=2.04]\n",
      "train epoch 148: 100%|██████████| 59/59 [00:00<00:00, 349.05batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 423.29batch/s, acc=0.533, loss=2.07]\n",
      "train epoch 149: 100%|██████████| 59/59 [00:00<00:00, 352.09batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 391.34batch/s, acc=0.521, loss=2.03]\n",
      "train epoch 150: 100%|██████████| 59/59 [00:00<00:00, 343.71batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.95batch/s, acc=0.531, loss=2.08]\n",
      "train epoch 151: 100%|██████████| 59/59 [00:00<00:00, 337.71batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 442.08batch/s, acc=0.524, loss=2.07]\n",
      "train epoch 152: 100%|██████████| 59/59 [00:00<00:00, 347.90batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 86.02batch/s, acc=0.532, loss=2.03]\n",
      "train epoch 153: 100%|██████████| 59/59 [00:00<00:00, 343.38batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 374.78batch/s, acc=0.525, loss=2.04]\n",
      "train epoch 154: 100%|██████████| 59/59 [00:00<00:00, 348.03batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 340.27batch/s, acc=0.532, loss=2.03]\n",
      "train epoch 155: 100%|██████████| 59/59 [00:00<00:00, 342.37batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 439.24batch/s, acc=0.533, loss=2.08]\n",
      "train epoch 156: 100%|██████████| 59/59 [00:00<00:00, 354.45batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 428.73batch/s, acc=0.528, loss=2.08]\n",
      "train epoch 157: 100%|██████████| 59/59 [00:00<00:00, 339.88batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 397.82batch/s, acc=0.533, loss=2.04]\n",
      "train epoch 158: 100%|██████████| 59/59 [00:00<00:00, 332.89batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 484.79batch/s, acc=0.531, loss=2.06]\n",
      "train epoch 159: 100%|██████████| 59/59 [00:00<00:00, 347.64batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.93batch/s, acc=0.533, loss=2.05]\n",
      "train epoch 160: 100%|██████████| 59/59 [00:00<00:00, 325.68batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 374.52batch/s, acc=0.539, loss=2.06]\n",
      "train epoch 161: 100%|██████████| 59/59 [00:00<00:00, 334.20batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 338.82batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 162: 100%|██████████| 59/59 [00:00<00:00, 326.55batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 422.93batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 163: 100%|██████████| 59/59 [00:00<00:00, 324.51batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 349.89batch/s, acc=0.531, loss=2.08]\n",
      "train epoch 164: 100%|██████████| 59/59 [00:00<00:00, 329.20batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 366.65batch/s, acc=0.526, loss=2.07]\n",
      "train epoch 165: 100%|██████████| 59/59 [00:00<00:00, 318.14batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 356.32batch/s, acc=0.534, loss=2.05]\n",
      "train epoch 166: 100%|██████████| 59/59 [00:00<00:00, 333.80batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 373.33batch/s, acc=0.536, loss=2.07]\n",
      "train epoch 167: 100%|██████████| 59/59 [00:00<00:00, 346.23batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 372.05batch/s, acc=0.539, loss=2.07]\n",
      "train epoch 168: 100%|██████████| 59/59 [00:00<00:00, 328.39batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 408.06batch/s, acc=0.53, loss=2.04]\n",
      "train epoch 169: 100%|██████████| 59/59 [00:00<00:00, 210.90batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 370.97batch/s, acc=0.535, loss=2.05]\n",
      "train epoch 170: 100%|██████████| 59/59 [00:00<00:00, 340.55batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 374.65batch/s, acc=0.535, loss=2.06]\n",
      "train epoch 171: 100%|██████████| 59/59 [00:00<00:00, 336.98batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.19batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 172: 100%|██████████| 59/59 [00:00<00:00, 332.37batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 404.40batch/s, acc=0.529, loss=2.08]\n",
      "train epoch 173: 100%|██████████| 59/59 [00:00<00:00, 327.74batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.54batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 174: 100%|██████████| 59/59 [00:00<00:00, 351.49batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 408.05batch/s, acc=0.524, loss=2.08]\n",
      "train epoch 175: 100%|██████████| 59/59 [00:00<00:00, 359.17batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.79batch/s, acc=0.529, loss=2.06]\n",
      "train epoch 176: 100%|██████████| 59/59 [00:00<00:00, 345.55batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.66batch/s, acc=0.531, loss=2.06]\n",
      "train epoch 177: 100%|██████████| 59/59 [00:00<00:00, 350.58batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 435.25batch/s, acc=0.529, loss=2.08]\n",
      "train epoch 178: 100%|██████████| 59/59 [00:00<00:00, 330.15batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 355.40batch/s, acc=0.527, loss=2.04]\n",
      "train epoch 179: 100%|██████████| 59/59 [00:00<00:00, 320.60batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 430.22batch/s, acc=0.531, loss=2.04]\n",
      "train epoch 180: 100%|██████████| 59/59 [00:00<00:00, 349.25batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 343.68batch/s, acc=0.534, loss=2.05]\n",
      "train epoch 181: 100%|██████████| 59/59 [00:00<00:00, 312.60batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 371.97batch/s, acc=0.529, loss=2.07]\n",
      "train epoch 182: 100%|██████████| 59/59 [00:00<00:00, 315.78batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 394.61batch/s, acc=0.527, loss=2.05]\n",
      "train epoch 183: 100%|██████████| 59/59 [00:00<00:00, 306.92batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 303.95batch/s, acc=0.527, loss=2.08]\n",
      "train epoch 184: 100%|██████████| 59/59 [00:00<00:00, 315.95batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 315.00batch/s, acc=0.53, loss=2.04]\n",
      "train epoch 185: 100%|██████████| 59/59 [00:00<00:00, 195.38batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 304.59batch/s, acc=0.53, loss=2.08]\n",
      "train epoch 186: 100%|██████████| 59/59 [00:00<00:00, 349.62batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 363.83batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 187: 100%|██████████| 59/59 [00:00<00:00, 347.52batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 369.84batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 188: 100%|██████████| 59/59 [00:00<00:00, 352.27batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 383.60batch/s, acc=0.533, loss=2.09]\n",
      "train epoch 189: 100%|██████████| 59/59 [00:00<00:00, 344.40batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 427.29batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 190: 100%|██████████| 59/59 [00:00<00:00, 330.94batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.24batch/s, acc=0.528, loss=2.09]\n",
      "train epoch 191: 100%|██████████| 59/59 [00:00<00:00, 349.50batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 443.99batch/s, acc=0.534, loss=2.07]\n",
      "train epoch 192: 100%|██████████| 59/59 [00:00<00:00, 354.10batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 420.84batch/s, acc=0.529, loss=2.1]\n",
      "train epoch 193: 100%|██████████| 59/59 [00:00<00:00, 365.29batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 417.34batch/s, acc=0.53, loss=2.08]\n",
      "train epoch 194: 100%|██████████| 59/59 [00:00<00:00, 373.11batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 320.21batch/s, acc=0.531, loss=2.05]\n",
      "train epoch 195: 100%|██████████| 59/59 [00:00<00:00, 321.64batch/s, loss=1.98]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 437.85batch/s, acc=0.533, loss=2.07]\n",
      "train epoch 196: 100%|██████████| 59/59 [00:00<00:00, 346.79batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 455.90batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 197: 100%|██████████| 59/59 [00:00<00:00, 343.02batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 433.99batch/s, acc=0.527, loss=2.11]\n",
      "train epoch 198: 100%|██████████| 59/59 [00:00<00:00, 354.86batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 396.96batch/s, acc=0.534, loss=2.07]\n",
      "train epoch 199: 100%|██████████| 59/59 [00:00<00:00, 367.14batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 341.96batch/s, acc=0.529, loss=2.06]\n",
      "train epoch 200: 100%|██████████| 59/59 [00:00<00:00, 366.17batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 394.50batch/s, acc=0.528, loss=2.09]\n",
      "train epoch 201: 100%|██████████| 59/59 [00:00<00:00, 218.84batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.31batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 202: 100%|██████████| 59/59 [00:00<00:00, 336.36batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 401.89batch/s, acc=0.53, loss=2.09]\n",
      "train epoch 203: 100%|██████████| 59/59 [00:00<00:00, 336.31batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 396.57batch/s, acc=0.532, loss=2.08]\n",
      "train epoch 204: 100%|██████████| 59/59 [00:00<00:00, 321.53batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 383.02batch/s, acc=0.529, loss=2.07]\n",
      "train epoch 205: 100%|██████████| 59/59 [00:00<00:00, 330.16batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 419.24batch/s, acc=0.529, loss=2.06]\n",
      "train epoch 206: 100%|██████████| 59/59 [00:00<00:00, 326.33batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.31batch/s, acc=0.525, loss=2.04]\n",
      "train epoch 207: 100%|██████████| 59/59 [00:00<00:00, 334.64batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 396.49batch/s, acc=0.535, loss=2.04]\n",
      "train epoch 208: 100%|██████████| 59/59 [00:00<00:00, 325.49batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 342.33batch/s, acc=0.526, loss=2.07]\n",
      "train epoch 209: 100%|██████████| 59/59 [00:00<00:00, 325.92batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 360.57batch/s, acc=0.527, loss=2.09]\n",
      "train epoch 210: 100%|██████████| 59/59 [00:00<00:00, 313.34batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.53batch/s, acc=0.524, loss=2.09]\n",
      "train epoch 211: 100%|██████████| 59/59 [00:00<00:00, 325.64batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 354.26batch/s, acc=0.528, loss=2.08]\n",
      "train epoch 212: 100%|██████████| 59/59 [00:00<00:00, 328.47batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 357.48batch/s, acc=0.531, loss=2.05]\n",
      "train epoch 213: 100%|██████████| 59/59 [00:00<00:00, 329.04batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 381.81batch/s, acc=0.533, loss=2.05]\n",
      "train epoch 214: 100%|██████████| 59/59 [00:00<00:00, 330.75batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.05batch/s, acc=0.533, loss=2.06]\n",
      "train epoch 215: 100%|██████████| 59/59 [00:00<00:00, 330.24batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 345.11batch/s, acc=0.523, loss=2.07]\n",
      "train epoch 216: 100%|██████████| 59/59 [00:00<00:00, 317.31batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 380.02batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 217: 100%|██████████| 59/59 [00:00<00:00, 203.98batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 470.06batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 218: 100%|██████████| 59/59 [00:00<00:00, 327.45batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 393.67batch/s, acc=0.532, loss=2.07]\n",
      "train epoch 219: 100%|██████████| 59/59 [00:00<00:00, 339.31batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.36batch/s, acc=0.533, loss=2.06]\n",
      "train epoch 220: 100%|██████████| 59/59 [00:00<00:00, 344.81batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 335.14batch/s, acc=0.531, loss=2.06]\n",
      "train epoch 221: 100%|██████████| 59/59 [00:00<00:00, 331.94batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 410.27batch/s, acc=0.525, loss=2.06]\n",
      "train epoch 222: 100%|██████████| 59/59 [00:00<00:00, 338.92batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 369.45batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 223: 100%|██████████| 59/59 [00:00<00:00, 336.50batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 429.33batch/s, acc=0.533, loss=2.08]\n",
      "train epoch 224: 100%|██████████| 59/59 [00:00<00:00, 325.65batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.45batch/s, acc=0.528, loss=2.07]\n",
      "train epoch 225: 100%|██████████| 59/59 [00:00<00:00, 330.86batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 395.19batch/s, acc=0.525, loss=2.04]\n",
      "train epoch 226: 100%|██████████| 59/59 [00:00<00:00, 337.43batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 346.71batch/s, acc=0.539, loss=2.06]\n",
      "train epoch 227: 100%|██████████| 59/59 [00:00<00:00, 335.01batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.19batch/s, acc=0.525, loss=2.05]\n",
      "train epoch 228: 100%|██████████| 59/59 [00:00<00:00, 337.20batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.13batch/s, acc=0.524, loss=2.08]\n",
      "train epoch 229: 100%|██████████| 59/59 [00:00<00:00, 338.05batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 401.17batch/s, acc=0.525, loss=2.04]\n",
      "train epoch 230: 100%|██████████| 59/59 [00:00<00:00, 313.53batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 424.66batch/s, acc=0.528, loss=2.04]\n",
      "train epoch 231: 100%|██████████| 59/59 [00:00<00:00, 317.50batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 422.40batch/s, acc=0.53, loss=2.08]\n",
      "train epoch 232: 100%|██████████| 59/59 [00:00<00:00, 318.81batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 350.11batch/s, acc=0.53, loss=2.1]\n",
      "train epoch 233: 100%|██████████| 59/59 [00:00<00:00, 208.95batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 368.06batch/s, acc=0.526, loss=2.09]\n",
      "train epoch 234: 100%|██████████| 59/59 [00:00<00:00, 337.83batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.70batch/s, acc=0.531, loss=2.09]\n",
      "train epoch 235: 100%|██████████| 59/59 [00:00<00:00, 327.57batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 363.79batch/s, acc=0.525, loss=2.06]\n",
      "train epoch 236: 100%|██████████| 59/59 [00:00<00:00, 326.27batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 347.16batch/s, acc=0.525, loss=2.06]\n",
      "train epoch 237: 100%|██████████| 59/59 [00:00<00:00, 337.12batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 436.69batch/s, acc=0.527, loss=2.06]\n",
      "train epoch 238: 100%|██████████| 59/59 [00:00<00:00, 329.33batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 369.17batch/s, acc=0.527, loss=2.09]\n",
      "train epoch 239: 100%|██████████| 59/59 [00:00<00:00, 322.34batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.14batch/s, acc=0.53, loss=2.09]\n",
      "train epoch 240: 100%|██████████| 59/59 [00:00<00:00, 338.18batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 420.36batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 241: 100%|██████████| 59/59 [00:00<00:00, 338.98batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 362.73batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 242: 100%|██████████| 59/59 [00:00<00:00, 324.20batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 406.86batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 243: 100%|██████████| 59/59 [00:00<00:00, 331.89batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 396.10batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 244: 100%|██████████| 59/59 [00:00<00:00, 303.90batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 322.24batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 245: 100%|██████████| 59/59 [00:00<00:00, 323.97batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 418.64batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 246: 100%|██████████| 59/59 [00:00<00:00, 336.43batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 426.34batch/s, acc=0.532, loss=2.04]\n",
      "train epoch 247: 100%|██████████| 59/59 [00:00<00:00, 342.65batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.82batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 248: 100%|██████████| 59/59 [00:00<00:00, 337.24batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 345.86batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 249: 100%|██████████| 59/59 [00:00<00:00, 327.30batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 87.18batch/s, acc=0.53, loss=2.04] \n",
      "train epoch 250: 100%|██████████| 59/59 [00:00<00:00, 336.59batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 403.36batch/s, acc=0.531, loss=2.05]\n",
      "train epoch 251: 100%|██████████| 59/59 [00:00<00:00, 347.65batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 378.30batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 252: 100%|██████████| 59/59 [00:00<00:00, 352.75batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 426.81batch/s, acc=0.534, loss=2.09]\n",
      "train epoch 253: 100%|██████████| 59/59 [00:00<00:00, 327.59batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.10batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 254: 100%|██████████| 59/59 [00:00<00:00, 308.92batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 402.79batch/s, acc=0.534, loss=2.04]\n",
      "train epoch 255: 100%|██████████| 59/59 [00:00<00:00, 313.34batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 345.36batch/s, acc=0.531, loss=2.08]\n",
      "train epoch 256: 100%|██████████| 59/59 [00:00<00:00, 318.81batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 373.16batch/s, acc=0.535, loss=2.04]\n",
      "train epoch 257: 100%|██████████| 59/59 [00:00<00:00, 348.23batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.29batch/s, acc=0.537, loss=2.06]\n",
      "train epoch 258: 100%|██████████| 59/59 [00:00<00:00, 335.33batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 425.13batch/s, acc=0.534, loss=2.02]\n",
      "train epoch 259: 100%|██████████| 59/59 [00:00<00:00, 343.48batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 336.72batch/s, acc=0.533, loss=2.05]\n",
      "train epoch 260: 100%|██████████| 59/59 [00:00<00:00, 333.61batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 451.09batch/s, acc=0.526, loss=2.07]\n",
      "train epoch 261: 100%|██████████| 59/59 [00:00<00:00, 338.18batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 316.63batch/s, acc=0.534, loss=2.04]\n",
      "train epoch 262: 100%|██████████| 59/59 [00:00<00:00, 340.54batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 406.21batch/s, acc=0.531, loss=2.06]\n",
      "train epoch 263: 100%|██████████| 59/59 [00:00<00:00, 330.65batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 384.68batch/s, acc=0.526, loss=2.03]\n",
      "train epoch 264: 100%|██████████| 59/59 [00:00<00:00, 344.50batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 405.91batch/s, acc=0.533, loss=2.06]\n",
      "train epoch 265: 100%|██████████| 59/59 [00:00<00:00, 318.96batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 355.38batch/s, acc=0.53, loss=2.07]\n",
      "train epoch 266: 100%|██████████| 59/59 [00:00<00:00, 210.56batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 403.91batch/s, acc=0.533, loss=2.04]\n",
      "train epoch 267: 100%|██████████| 59/59 [00:00<00:00, 332.93batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 388.28batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 268: 100%|██████████| 59/59 [00:00<00:00, 336.96batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 447.32batch/s, acc=0.527, loss=2.06]\n",
      "train epoch 269: 100%|██████████| 59/59 [00:00<00:00, 343.46batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 448.26batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 270: 100%|██████████| 59/59 [00:00<00:00, 332.37batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 453.56batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 271: 100%|██████████| 59/59 [00:00<00:00, 348.87batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 409.61batch/s, acc=0.528, loss=2.06]\n",
      "train epoch 272: 100%|██████████| 59/59 [00:00<00:00, 345.43batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 390.23batch/s, acc=0.523, loss=2.04]\n",
      "train epoch 273: 100%|██████████| 59/59 [00:00<00:00, 346.22batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 358.88batch/s, acc=0.527, loss=2.06]\n",
      "train epoch 274: 100%|██████████| 59/59 [00:00<00:00, 331.11batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.59batch/s, acc=0.525, loss=2.07]\n",
      "train epoch 275: 100%|██████████| 59/59 [00:00<00:00, 324.78batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.79batch/s, acc=0.526, loss=2.07]\n",
      "train epoch 276: 100%|██████████| 59/59 [00:00<00:00, 327.96batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 471.19batch/s, acc=0.533, loss=2.08]\n",
      "train epoch 277: 100%|██████████| 59/59 [00:00<00:00, 324.96batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 376.47batch/s, acc=0.529, loss=2.1]\n",
      "train epoch 278: 100%|██████████| 59/59 [00:00<00:00, 332.16batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 414.53batch/s, acc=0.532, loss=2.06]\n",
      "train epoch 279: 100%|██████████| 59/59 [00:00<00:00, 328.85batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 386.69batch/s, acc=0.531, loss=2.04]\n",
      "train epoch 280: 100%|██████████| 59/59 [00:00<00:00, 331.00batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 455.70batch/s, acc=0.533, loss=2.05]\n",
      "train epoch 281: 100%|██████████| 59/59 [00:00<00:00, 331.03batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 314.06batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 282: 100%|██████████| 59/59 [00:00<00:00, 211.27batch/s, loss=1.99]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 400.91batch/s, acc=0.532, loss=2.07]\n",
      "train epoch 283: 100%|██████████| 59/59 [00:00<00:00, 326.61batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 381.98batch/s, acc=0.531, loss=2.04]\n",
      "train epoch 284: 100%|██████████| 59/59 [00:00<00:00, 345.32batch/s, loss=2.06]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.43batch/s, acc=0.524, loss=2.03]\n",
      "train epoch 285: 100%|██████████| 59/59 [00:00<00:00, 319.93batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 344.59batch/s, acc=0.532, loss=2.07]\n",
      "train epoch 286: 100%|██████████| 59/59 [00:00<00:00, 337.55batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 392.30batch/s, acc=0.53, loss=2.08]\n",
      "train epoch 287: 100%|██████████| 59/59 [00:00<00:00, 342.81batch/s, loss=2.01]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 417.07batch/s, acc=0.526, loss=2.08]\n",
      "train epoch 288: 100%|██████████| 59/59 [00:00<00:00, 337.48batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 333.10batch/s, acc=0.531, loss=2.07]\n",
      "train epoch 289: 100%|██████████| 59/59 [00:00<00:00, 336.16batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 345.01batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 290: 100%|██████████| 59/59 [00:00<00:00, 344.89batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 531.78batch/s, acc=0.528, loss=2.05]\n",
      "train epoch 291: 100%|██████████| 59/59 [00:00<00:00, 334.38batch/s, loss=2.04]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 359.04batch/s, acc=0.53, loss=2.04]\n",
      "train epoch 292: 100%|██████████| 59/59 [00:00<00:00, 332.21batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 367.15batch/s, acc=0.525, loss=2.06]\n",
      "train epoch 293: 100%|██████████| 59/59 [00:00<00:00, 329.32batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 362.66batch/s, acc=0.527, loss=2.06]\n",
      "train epoch 294: 100%|██████████| 59/59 [00:00<00:00, 338.65batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 353.92batch/s, acc=0.53, loss=2.06]\n",
      "train epoch 295: 100%|██████████| 59/59 [00:00<00:00, 334.41batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 310.41batch/s, acc=0.522, loss=2.08]\n",
      "train epoch 296: 100%|██████████| 59/59 [00:00<00:00, 341.03batch/s, loss=2.03]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 399.19batch/s, acc=0.531, loss=2.06]\n",
      "train epoch 297: 100%|██████████| 59/59 [00:00<00:00, 338.77batch/s, loss=2.05]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 389.61batch/s, acc=0.525, loss=2.06]\n",
      "train epoch 298: 100%|██████████| 59/59 [00:00<00:00, 205.12batch/s, loss=2.07]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 453.29batch/s, acc=0.533, loss=2.05]\n",
      "train epoch 299: 100%|██████████| 59/59 [00:00<00:00, 333.97batch/s, loss=2.02]\n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 346.39batch/s, acc=0.532, loss=2.05]\n",
      "train epoch 300: 100%|██████████| 59/59 [00:00<00:00, 337.32batch/s, loss=2]   \n",
      "eval: 100%|██████████| 12/12 [00:00<00:00, 403.96batch/s, acc=0.531, loss=2.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 47/47 [00:00<00:00, 398.61batch/s, acc=0.525, loss=2.05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 12/12 [00:00<00:00, 325.71batch/s, acc=0.531, loss=2.04]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "retain:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 43/43 [00:00<00:00, 425.38batch/s, acc=0.527, loss=2.06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "forget:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 5/5 [00:00<00:00, 536.91batch/s, acc=0.51, loss=2.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "surrogate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 59/59 [00:00<00:00, 435.52batch/s, acc=0.61, loss=2.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:56:42.371851Z",
     "start_time": "2024-12-30T01:50:20.330746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# forget with exact\n",
    "model = model.to(device)\n",
    "# fmodel = forget(model, train_loader, forget_loader, forget_loader, criterion, save_path='tmp', eps=eps, delta=delta)\n",
    "fmodel = forget(model, train_loader, forget_loader, forget_loader, criterion, save_path='tmp')\n",
    "model = model.to('cpu')\n",
    "print_eval(fmodel)\n",
    "fmodel = fmodel.to('cpu')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Hessian: 100%|██████████| 47/47 [05:44<00:00,  7.34s/it]\n",
      "Calculating Hessian: 100%|██████████| 5/5 [00:36<00:00,  7.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 47/47 [00:00<00:00, 561.34batch/s, acc=0.616, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "val:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 12/12 [00:00<00:00, 558.75batch/s, acc=0.537, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "retain:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 43/43 [00:00<00:00, 562.01batch/s, acc=0.622, loss=1.99]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "forget:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 5/5 [00:00<00:00, 554.16batch/s, acc=0.56, loss=2.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n",
      "#######################################\n",
      "surrogate:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "eval: 100%|██████████| 59/59 [00:00<00:00, 555.95batch/s, acc=0.575, loss=2.07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T01:56:42.707725Z",
     "start_time": "2024-12-30T01:56:42.373072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# forget with surrogate\n",
    "# forget with exact\n",
    "model = model.to(device)\n",
    "surrmodel = surrmodel.to(device)\n",
    "smodel = forget(model, surr_loader, forget_loader, forget_loader, criterion, linear=True, num_class=num_classes, eps=eps, delta=delta, surr=True, known=True, surr_loader=surr_loader, surr_model=surrmodel, kl_distance=kl_distance)\n",
    "model = model.to('cpu')\n",
    "print_eval(smodel)\n",
    "smodel = smodel.to('cpu')"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forget() got an unexpected keyword argument 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      4\u001B[0m surrmodel \u001B[38;5;241m=\u001B[39m surrmodel\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 5\u001B[0m smodel \u001B[38;5;241m=\u001B[39m forget(model, surr_loader, forget_loader, forget_loader, criterion, linear\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_class\u001B[38;5;241m=\u001B[39mnum_classes, eps\u001B[38;5;241m=\u001B[39meps, delta\u001B[38;5;241m=\u001B[39mdelta, surr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, known\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, surr_loader\u001B[38;5;241m=\u001B[39msurr_loader, surr_model\u001B[38;5;241m=\u001B[39msurrmodel, kl_distance\u001B[38;5;241m=\u001B[39mkl_distance)\n\u001B[1;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m print_eval(smodel)\n",
      "\u001B[0;31mTypeError\u001B[0m: forget() got an unexpected keyword argument 'linear'"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icml25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
